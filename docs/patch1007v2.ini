diff --git a/scripts/demo_operability_integration.py b/scripts/demo_operability_integration.py
index 3ee64af0a0cdfbeebfc5ccdc1f327b8c7a8c2937..d25f0d562c12f54ba2fb1b05be3da8e5e6923117 100644
--- a/scripts/demo_operability_integration.py
+++ b/scripts/demo_operability_integration.py
@@ -1,287 +1,264 @@
 #!/usr/bin/env python3
-"""
-KR: í†µí•©ëœ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ë°ëª¨
-EN: Integrated operability prediction demo
-
-ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” HVDC í•´ì–‘ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œê³¼ operability_packageë¥¼ í†µí•©í•˜ì—¬
-ì‹¤ì œ ê¸°ìƒ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
-"""
+"""KR: ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ë°ëª¨ / EN: Operability prediction demo."""
 
+import argparse
+import os
 import sys
 import json
 import pandas as pd
 from pathlib import Path
-from datetime import datetime, timedelta
-from typing import List, Dict, Any
+from datetime import datetime, timedelta, timezone
+from typing import Any, Dict, List, Tuple
 
 # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
 project_root = Path(__file__).parent.parent
 sys.path.insert(0, str(project_root))
 
-from src.marine_ops.core.schema import MarineTimeseries, MarineDataPoint
-from src.marine_ops.operability.api import OperabilityPredictor, create_operability_report
+from src.marine_ops.core.schema import MarineTimeseries
+from src.marine_ops.operability.api import create_operability_report
 from src.marine_ops.connectors.stormglass import StormglassConnector
 from src.marine_ops.connectors.open_meteo import OpenMeteoConnector
-from src.marine_ops.connectors.worldtides import fetch_worldtides_heights, create_marine_timeseries_from_worldtides
-from src.marine_ops.eri.compute import ERICalculator
+from src.marine_ops.connectors.worldtides import create_marine_timeseries_from_worldtides
+from scripts.offline_support import decide_execution_mode, generate_offline_dataset
+
+def collect_weather_data(mode: str = "auto") -> Tuple[List[MarineTimeseries], str, List[str]]:
+    """KR: ê¸°ìƒ ë°ì´í„° ìˆ˜ì§‘ / EN: Collect marine weather data."""
 
-def collect_weather_data() -> List[MarineTimeseries]:
-    """ì‹¤ì œ ê¸°ìƒ ë°ì´í„° ìˆ˜ì§‘"""
     print("ğŸŒŠ ê¸°ìƒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
-    
-    weather_data = []
-    
-    # UAE í•´ì—­ ì¢Œí‘œ (Dubai ê·¼ì²˜)
+
     lat, lon = 25.2048, 55.2708
-    
-    try:
-        # Stormglass ë°ì´í„° ìˆ˜ì§‘
-        print("  ğŸ“¡ Stormglass APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘...")
-        sg_connector = StormglassConnector()
-        sg_data = sg_connector.get_marine_weather(lat, lon, days=7)
-        if sg_data and sg_data.data_points:
-            weather_data.append(sg_data)
-            print(f"    âœ… {len(sg_data.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ì§‘")
-        else:
-            print("    âš ï¸ Stormglass ë°ì´í„° ì—†ìŒ")
-    except Exception as e:
-        print(f"    âŒ Stormglass ì˜¤ë¥˜: {e}")
-    
+    forecast_hours = 24 * 7
+    start_time = datetime.now(timezone.utc)
+    end_time = start_time + timedelta(hours=forecast_hours)
+    required_secrets = ["STORMGLASS_API_KEY", "WORLDTIDES_API_KEY"]
+    missing_secrets = [key for key in required_secrets if not os.getenv(key)]
+    resolved_mode, offline_reasons = decide_execution_mode(mode, missing_secrets, ncm_available=True)
+
+    if resolved_mode == "offline":
+        synthetic_series, _ = generate_offline_dataset("UAE_Waters", forecast_hours)
+        if offline_reasons:
+            print(f"âš ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì „í™˜: {', '.join(offline_reasons)}")
+        return synthetic_series, resolved_mode, offline_reasons
+
+    weather_data: List[MarineTimeseries] = []
+
+    stormglass_key = os.getenv("STORMGLASS_API_KEY", "")
+    if stormglass_key:
+        try:
+            print("  ğŸ“¡ Stormglass APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘...")
+            sg_connector = StormglassConnector(api_key=stormglass_key)
+            sg_data = sg_connector.get_marine_weather(
+                lat,
+                lon,
+                start_time,
+                end_time,
+                location="UAE_Waters",
+            )
+            if sg_data and sg_data.data_points:
+                weather_data.append(sg_data)
+                print(f"    âœ… {len(sg_data.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ì§‘")
+            else:
+                print("    âš ï¸ Stormglass ë°ì´í„° ì—†ìŒ")
+        except Exception as error:
+            print(f"    âŒ Stormglass ì˜¤ë¥˜: {error}")
+    else:
+        print("  âš ï¸ Stormglass API í‚¤ ì—†ìŒìœ¼ë¡œ ê±´ë„ˆëœ€")
+
     try:
-        # Open-Meteo ë°ì´í„° ìˆ˜ì§‘
         print("  ğŸ“¡ Open-Meteo APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘...")
         om_connector = OpenMeteoConnector()
-        om_data = om_connector.get_marine_weather(lat, lon, days=7)
+        om_data = om_connector.get_marine_weather(
+            lat,
+            lon,
+            start_time,
+            end_time,
+            location="UAE_Waters",
+        )
         if om_data and om_data.data_points:
             weather_data.append(om_data)
             print(f"    âœ… {len(om_data.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ì§‘")
         else:
             print("    âš ï¸ Open-Meteo ë°ì´í„° ì—†ìŒ")
-    except Exception as e:
-        print(f"    âŒ Open-Meteo ì˜¤ë¥˜: {e}")
-    
-    try:
-        # WorldTides ë°ì´í„° ìˆ˜ì§‘
-        print("  ğŸ“¡ WorldTides APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘...")
-        wt_key = "a7b5bd88-041e-4316-8f8e-02670eb44bc7"  # API í‚¤
-        wt_raw = fetch_worldtides_heights(lat, lon, wt_key, hours=168)  # 7ì¼
-        if wt_raw and 'heights' in wt_raw:
-            wt_data = create_marine_timeseries_from_worldtides(wt_raw, lat, lon)
+    except Exception as error:
+        print(f"    âŒ Open-Meteo ì˜¤ë¥˜: {error}")
+
+    worldtides_key = os.getenv("WORLDTIDES_API_KEY", "")
+    if worldtides_key:
+        try:
+            print("  ğŸ“¡ WorldTides APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘...")
+            wt_data = create_marine_timeseries_from_worldtides(
+                lat,
+                lon,
+                worldtides_key,
+                forecast_hours,
+                "UAE_Waters",
+            )
             if wt_data and wt_data.data_points:
                 weather_data.append(wt_data)
                 print(f"    âœ… {len(wt_data.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ì§‘")
             else:
-                print("    âš ï¸ WorldTides ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨")
-        else:
-            print("    âš ï¸ WorldTides ë°ì´í„° ì—†ìŒ")
-    except Exception as e:
-        print(f"    âŒ WorldTides ì˜¤ë¥˜: {e}")
-    
-    print(f"ğŸ“Š ì´ {len(weather_data)}ê°œ ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
-    return weather_data
+                print("    âš ï¸ WorldTides ë°ì´í„° ì—†ìŒ")
+        except Exception as error:
+            print(f"    âŒ WorldTides ì˜¤ë¥˜: {error}")
+    else:
+        print("  âš ï¸ WorldTides API í‚¤ ì—†ìŒìœ¼ë¡œ ê±´ë„ˆëœ€")
 
-def create_synthetic_ensemble_data() -> List[MarineTimeseries]:
-    """í•©ì„± ì•™ìƒë¸” ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„°ê°€ ë¶€ì¡±í•  ê²½ìš°)"""
-    print("ğŸ² í•©ì„± ì•™ìƒë¸” ë°ì´í„° ìƒì„±...")
-    
-    import random
-    import numpy as np
-    from datetime import datetime, timedelta
-    
-    random.seed(42)
-    np.random.seed(42)
-    
-    # 7ì¼ê°„ì˜ ì‹œê°„ë³„ ë°ì´í„° ìƒì„±
-    data_points = []
-    base_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
-    
-    for day in range(7):
-        for hour in range(0, 24, 3):  # 3ì‹œê°„ ê°„ê²©
-            timestamp = base_time + timedelta(days=day, hours=hour)
-            
-            # ì‹œê°„ê³¼ ë‚ ì§œì— ë”°ë¥¸ íŒŒë¼ë¯¸í„° ë³€í™”
-            day_factor = 1 + (day * 0.05)  # ë‚ ì´ ì§€ë‚ ìˆ˜ë¡ ì¡°ê±´ ì•…í™”
-            hour_factor = 1 + 0.1 * np.sin(hour / 4.0)  # ì‹œê°„ì— ë”°ë¥¸ ë³€í™”
-            
-            # íŒŒê³  (Hs) ìƒì„±
-            hs_base = 0.8 + (day * 0.1) * hour_factor
-            hs = max(0.1, np.random.normal(hs_base, 0.2))
-            
-            # í’ì† ìƒì„±
-            wind_base = 15.0 + (day * 0.5) * hour_factor
-            wind = max(0.5, np.random.normal(wind_base, 3.0))
-            
-            # í’í–¥ ìƒì„±
-            wind_dir = np.random.uniform(0, 360)
-            
-            data_point = MarineDataPoint(
-                timestamp=timestamp.isoformat(),
-                wind_speed=wind,
-                wind_direction=wind_dir,
-                wave_height=hs,
-                wave_period=np.random.uniform(6, 12),
-                wave_direction=wind_dir + np.random.uniform(-30, 30),
-                sea_state="Moderate" if hs < 1.5 else "Rough",
-                visibility=np.random.uniform(8, 15),
-                temperature=np.random.uniform(22, 28),
-                confidence=0.7  # í•©ì„± ë°ì´í„° ì‹ ë¢°ë„
-            )
-            data_points.append(data_point)
-    
-    # MarineTimeseries ê°ì²´ ìƒì„±
-    synthetic_timeseries = MarineTimeseries(
-        source="synthetic_ensemble",
-        location="UAE_Waters",
-        data_points=data_points,
-        ingested_at=datetime.now().isoformat()
-    )
-    
-    print(f"    âœ… {len(data_points)}ê°œ í•©ì„± ë°ì´í„° í¬ì¸íŠ¸ ìƒì„±")
-    return [synthetic_timeseries]
+    if not weather_data:
+        print("âš ï¸ ì™¸ë¶€ ë°ì´í„°ê°€ ì—†ì–´ í•©ì„± ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
+        synthetic_series, _ = generate_offline_dataset("UAE_Waters", forecast_hours)
+        weather_data = synthetic_series
+        offline_reasons.append("ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
+        resolved_mode = "offline"
+
+    print(f"ğŸ“Š ì´ {len(weather_data)}ê°œ ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
+    return weather_data, resolved_mode, offline_reasons
 
 def run_operability_prediction(weather_data: List[MarineTimeseries]) -> Dict[str, Any]:
-    """ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰"""
+    """KR: ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰ / EN: Run operability prediction."""
     print("ğŸš¢ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
     
     # í•­ë¡œ ì •ë³´ ì •ì˜
     routes = [
         {
             "name": "Abu Dhabi to AGI or DAS",
             "distance_nm": 65.0,
             "planned_speed_kt": 12.0,
             "hs_forecast": 1.2
         }
     ]
     
     # ìš´í•­ ê°€ëŠ¥ì„± ë³´ê³ ì„œ ìƒì„±
     report = create_operability_report(
         weather_data=weather_data,
         routes=routes,
         forecast_days=7
     )
     
     print(f"    âœ… {len(report['operability_forecasts'])}ê°œ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì™„ë£Œ")
     print(f"    âœ… {len(report['eta_predictions'])}ê°œ ETA ì˜ˆì¸¡ ì™„ë£Œ")
     
     return report
 
 def save_results(report: Dict[str, Any], output_dir: Path):
-    """ê²°ê³¼ ì €ì¥"""
+    """KR: ê²°ê³¼ ì €ì¥ / EN: Persist results."""
     print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
     
     # JSON ë³´ê³ ì„œ ì €ì¥
     json_file = output_dir / "operability_report.json"
     with open(json_file, 'w', encoding='utf-8') as f:
         json.dump(report, f, indent=2, ensure_ascii=False, default=str)
     print(f"  âœ… JSON ë³´ê³ ì„œ: {json_file}")
     
     # CSV í˜•ì‹ìœ¼ë¡œ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì €ì¥
     if report['operability_forecasts']:
         csv_data = []
         for forecast in report['operability_forecasts']:
             csv_data.append({
                 'day': forecast.day,
                 'daypart': forecast.daypart,
                 'P_go': forecast.probabilities.P_go,
                 'P_cond': forecast.probabilities.P_cond,
                 'P_nogo': forecast.probabilities.P_nogo,
                 'decision': forecast.decision,
                 'confidence': forecast.confidence,
                 'gate_hs_go': forecast.gate_used.hs_go,
                 'gate_wind_go': forecast.gate_used.wind_go
             })
         
         df_forecasts = pd.DataFrame(csv_data)
         csv_file = output_dir / "operability_forecasts.csv"
         df_forecasts.to_csv(csv_file, index=False)
         print(f"  âœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ CSV: {csv_file}")
     
     # ETA ì˜ˆì¸¡ CSV ì €ì¥
     if report['eta_predictions']:
         eta_data = []
         for eta in report['eta_predictions']:
             eta_data.append({
                 'route': eta.route,
                 'distance_nm': eta.distance_nm,
                 'planned_speed_kt': eta.planned_speed_kt,
                 'effective_speed_kt': eta.effective_speed_kt,
                 'eta_hours': eta.eta_hours,
                 'buffer_minutes': eta.buffer_minutes,
                 'hs_impact': eta.hs_impact
             })
         
         df_eta = pd.DataFrame(eta_data)
         eta_csv_file = output_dir / "eta_predictions.csv"
         df_eta.to_csv(eta_csv_file, index=False)
         print(f"  âœ… ETA ì˜ˆì¸¡ CSV: {eta_csv_file}")
 
 def print_summary(report: Dict[str, Any]):
-    """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
+    """KR: ê²°ê³¼ ìš”ì•½ ì¶œë ¥ / EN: Print result summary."""
     print("\n" + "="*60)
     print("ğŸ“Š ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½")
     print("="*60)
     
     summary = report['summary']
     print(f"ğŸ“… ì˜ˆì¸¡ ê¸°ê°„: {report['forecast_days']}ì¼")
     print(f"ğŸ“ˆ ì´ ì˜ˆì¸¡ ìˆ˜: {summary['total_forecasts']}")
     print(f"âœ… GO: {summary['go_count']}ê°œ")
     print(f"âš ï¸  CONDITIONAL: {summary['conditional_count']}ê°œ")
     print(f"âŒ NO-GO: {summary['nogo_count']}ê°œ")
     print(f"ğŸ¯ í‰ê·  ì‹ ë¢°ë„: {summary['average_confidence']:.2f}")
     
     print("\nğŸš¢ ETA ì˜ˆì¸¡:")
     for eta in report['eta_predictions']:
         print(f"  â€¢ {eta.route}: {eta.eta_hours:.1f}ì‹œê°„ "
               f"(ê³„íš: {eta.planned_speed_kt}kt â†’ ì‹¤ì œ: {eta.effective_speed_kt:.1f}kt)")
     
     print("\nğŸ“‹ ì¼ë³„ ìš´í•­ ê°€ëŠ¥ì„± (ìµœì†Œ P_go):")
     day_summary = {}
     for forecast in report['operability_forecasts']:
         day = forecast.day
         if day not in day_summary:
             day_summary[day] = []
         day_summary[day].append(forecast.probabilities.P_go)
     
     for day in sorted(day_summary.keys()):
         min_p_go = min(day_summary[day])
         status = "ğŸŸ¢" if min_p_go > 0.5 else "ğŸŸ¡" if min_p_go > 0.3 else "ğŸ”´"
         print(f"  {status} {day}: P(Go) = {min_p_go:.2f}")
 
-def main():
-    """ë©”ì¸ í•¨ìˆ˜"""
+def parse_args() -> argparse.Namespace:
+    """KR: CLI ì¸ì íŒŒì‹± / EN: Parse CLI arguments."""
+
+    parser = argparse.ArgumentParser(description="HVDC Marine operability demo")
+    parser.add_argument("--mode", choices=["auto", "online", "offline"], default="auto", help="ì‹¤í–‰ ëª¨ë“œ (auto/online/offline)")
+    parser.add_argument("--output", default="out", help="ê²°ê³¼ ì¶œë ¥ ë””ë ‰í„°ë¦¬")
+    return parser.parse_args()
+
+
+def main() -> None:
+    """KR: ë°ëª¨ ì‹¤í–‰ / EN: Run demo."""
+
+    args = parse_args()
+
     print("ğŸš¢ HVDC í•´ì–‘ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
-    print("="*50)
-    
-    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
-    output_dir = Path("out")
-    output_dir.mkdir(exist_ok=True)
-    
+    print("=" * 50)
+
+    output_dir = Path(args.output)
+    output_dir.mkdir(exist_ok=True, parents=True)
+
     try:
-        # 1. ê¸°ìƒ ë°ì´í„° ìˆ˜ì§‘
-        weather_data = collect_weather_data()
-        
-        # ì‹¤ì œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ í•©ì„± ë°ì´í„° ì¶”ê°€
-        if len(weather_data) == 0 or sum(len(ts.data_points) for ts in weather_data) < 50:
-            print("âš ï¸ ì‹¤ì œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ í•©ì„± ë°ì´í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤...")
-            synthetic_data = create_synthetic_ensemble_data()
-            weather_data.extend(synthetic_data)
-        
-        # 2. ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰
+        weather_data, resolved_mode, offline_reasons = collect_weather_data(args.mode)
+        print(f"âš™ï¸ ì‹¤í–‰ ëª¨ë“œ: {resolved_mode}")
+        if offline_reasons:
+            print("  â†³ ì‚¬ìœ : " + ", ".join(offline_reasons))
+
         report = run_operability_prediction(weather_data)
-        
-        # 3. ê²°ê³¼ ì €ì¥
         save_results(report, output_dir)
-        
-        # 4. ìš”ì•½ ì¶œë ¥
         print_summary(report)
-        
+
         print(f"\nâœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ëŠ” {output_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
-        
-    except Exception as e:
-        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
+
+    except Exception as error:
+        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {error}")
         import traceback
         traceback.print_exc()
         sys.exit(1)
 
+
 if __name__ == "__main__":
     main()
diff --git a/scripts/offline_support.py b/scripts/offline_support.py
new file mode 100644
index 0000000000000000000000000000000000000000..83f8a7804ff0191f37da949aa1f402cd31b8b7a0
--- /dev/null
+++ b/scripts/offline_support.py
@@ -0,0 +1,90 @@
+"""KR: GitHub Actionsìš© ì˜¤í”„ë¼ì¸ ì§€ì› ìœ í‹¸ / EN: Offline support utilities for GitHub Actions."""
+from __future__ import annotations
+
+import os
+import math
+from datetime import datetime, timedelta, timezone
+from typing import Dict, List, Sequence, Tuple
+
+from src.marine_ops.core.schema import MarineDataPoint, MarineTimeseries
+
+
+def decide_execution_mode(requested_mode: str, missing_secrets: Sequence[str], ncm_available: bool) -> Tuple[str, List[str]]:
+    """KR: ì‹¤í–‰ ëª¨ë“œ ê²°ì • / EN: Decide execution mode."""
+
+    normalized = requested_mode.lower()
+    if normalized not in {"auto", "online", "offline"}:
+        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹¤í–‰ ëª¨ë“œì…ë‹ˆë‹¤: {requested_mode}")
+
+    reasons: List[str] = []
+
+    if normalized == "offline":
+        reasons.append("ì‚¬ìš©ì ì§€ì • ì˜¤í”„ë¼ì¸ ëª¨ë“œ")
+        return "offline", reasons
+
+    if normalized == "online":
+        return "online", reasons
+
+    if os.getenv("CI", "").lower() == "true":
+        reasons.append("CI í™˜ê²½ ìë™ ì „í™˜")
+
+    if missing_secrets:
+        reasons.append(f"í•„ìˆ˜ ì‹œí¬ë¦¿ ëˆ„ë½: {', '.join(missing_secrets)}")
+
+    if not ncm_available:
+        reasons.append("NCM Selenium ëª¨ë“ˆ ë¯¸ë¡œë“œ")
+
+    resolved_mode = "offline" if reasons else "online"
+    return resolved_mode, reasons
+
+
+def generate_offline_dataset(location: str, forecast_hours: int) -> Tuple[List[MarineTimeseries], Dict[str, Dict[str, float]]]:
+    """KR: í•©ì„± í•´ì–‘ ì‹œê³„ì—´ ìƒì„± / EN: Generate synthetic marine timeseries."""
+    now = datetime.now(timezone.utc).replace(minute=0, second=0, microsecond=0)
+    data_points: List[MarineDataPoint] = []
+
+    for hour in range(max(forecast_hours, 6)):
+        timestamp = now + timedelta(hours=hour)
+        phase = hour / 6.0
+        wind_speed = 8.5 + 1.8 * math.sin(phase)
+        wind_direction = (120 + 20 * math.cos(phase * 0.8)) % 360
+        wind_gust = wind_speed * 1.15
+        wave_height = 0.6 + 0.25 * math.sin(phase + 0.6)
+        wave_period = 7.5 + 0.4 * math.cos(phase)
+        visibility = 11.0 - 0.8 * math.sin(phase * 0.5)
+        temperature = 27.0 - 0.6 * math.cos(phase * 0.9)
+        sea_state = "Slight" if wave_height < 1.0 else "Moderate"
+
+        data_points.append(
+            MarineDataPoint(
+                timestamp=timestamp.isoformat(),
+                wind_speed=round(wind_speed, 2),
+                wind_direction=round(wind_direction, 2),
+                wave_height=round(wave_height, 2),
+                wind_gust=round(wind_gust, 2),
+                wave_period=round(wave_period, 2),
+                wave_direction=round((wind_direction + 5) % 360, 2),
+                sea_state=sea_state,
+                visibility=round(max(4.0, visibility), 2),
+                temperature=round(temperature, 2),
+                confidence=0.7,
+            )
+        )
+
+    synthetic_series = MarineTimeseries(
+        source="synthetic_offline",
+        location=location,
+        data_points=data_points,
+        ingested_at=datetime.now(timezone.utc).isoformat(),
+        confidence=0.7,
+    )
+
+    statuses: Dict[str, Dict[str, float]] = {
+        "STORMGLASS": {"status": "âš ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ", "confidence": 0.0},
+        "OPEN_METEO": {"status": "âš ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ", "confidence": 0.0},
+        "NCM_SELENIUM": {"status": "âš ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ", "confidence": 0.0},
+        "WORLDTIDES": {"status": "âš ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ", "confidence": 0.0},
+        "SYNTHETIC": {"status": "âœ… ì˜¤í”„ë¼ì¸ í•©ì„± ë°ì´í„°", "confidence": synthetic_series.confidence or 0.7},
+    }
+
+    return [synthetic_series], statuses
diff --git a/scripts/weather_job.py b/scripts/weather_job.py
index 27b12faf118ed05277a848f71abc0a1268f8afde..b8e127372794d0c70f6e74973a883d67f04577fe 100644
--- a/scripts/weather_job.py
+++ b/scripts/weather_job.py
@@ -1,147 +1,189 @@
 #!/usr/bin/env python3
 """
 GitHub Actionsìš© í•´ì–‘ ë‚ ì”¨ ì‘ì—… ìŠ¤í¬ë¦½íŠ¸
 ë§¤ì‹œê°„ ì‹¤í–‰ë˜ì–´ í•´ì–‘ ë‚ ì”¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 """
 
 import os
 import sys
 import json
 import argparse
 from pathlib import Path
 from datetime import datetime, timedelta
+from typing import List
+
 import pandas as pd
 
 # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
 project_root = Path(__file__).parent.parent
 sys.path.insert(0, str(project_root))
 
 from src.marine_ops.connectors.stormglass import StormglassConnector, LOCATIONS as SG_LOCATIONS
 from src.marine_ops.connectors.open_meteo import OpenMeteoConnector
 from src.marine_ops.connectors.worldtides import create_marine_timeseries_from_worldtides
-from ncm_web.ncm_selenium_ingestor import NCMSeleniumIngestor
 from src.marine_ops.eri.compute import ERICalculator
 from src.marine_ops.decision.fusion import ForecastFusion, OperationalDecisionMaker
-from src.marine_ops.core.schema import MarineTimeseries, MarineDataPoint, OperationalDecision, ERIPoint
+from src.marine_ops.core.schema import MarineTimeseries, ERIPoint
+from scripts.offline_support import decide_execution_mode, generate_offline_dataset
+
+try:
+    from ncm_web.ncm_selenium_ingestor import NCMSeleniumIngestor
 
+    NCM_IMPORT_ERROR: Exception | None = None
+except Exception as import_error:  # pragma: no cover - import guard
+    NCMSeleniumIngestor = None  # type: ignore[assignment]
+    NCM_IMPORT_ERROR = import_error
 def load_config(config_path: str) -> dict:
     """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
     try:
         with open(config_path, 'r', encoding='utf-8') as f:
             if config_path.endswith('.yml') or config_path.endswith('.yaml'):
                 import yaml
                 return yaml.safe_load(f)
             else:
                 return json.load(f)
     except FileNotFoundError:
         print(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
         return {}
 
-def collect_weather_data(location_name: str = "AGI", forecast_hours: int = 24) -> dict:
+def collect_weather_data(location_name: str = "AGI", forecast_hours: int = 24, mode: str = "auto") -> dict:
     """í•´ì–‘ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘"""
     print(f"ğŸŒŠ {location_name} í•´ì—­ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
-    
+
     lat, lon = SG_LOCATIONS[location_name]['lat'], SG_LOCATIONS[location_name]['lon']
     now = datetime.now()
     end_date = now + timedelta(hours=forecast_hours)
-    
-    all_timeseries = []
-    api_status = {}
-    
+
+    required_secrets = ["STORMGLASS_API_KEY", "WORLDTIDES_API_KEY"]
+    missing_secrets = [key for key in required_secrets if not os.getenv(key)]
+    resolved_mode, offline_reasons = decide_execution_mode(mode, missing_secrets, NCMSeleniumIngestor is not None)
+
+    if resolved_mode == "offline":
+        synthetic_series, statuses = generate_offline_dataset(location_name, forecast_hours)
+        if offline_reasons:
+            print(f"âš ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì „í™˜: {', '.join(offline_reasons)}")
+        return {
+            'timeseries': synthetic_series,
+            'api_status': statuses,
+            'location': location_name,
+            'forecast_hours': forecast_hours,
+            'collected_at': now.isoformat(),
+            'mode': resolved_mode,
+            'offline_reasons': offline_reasons,
+        }
+
+    all_timeseries: List[MarineTimeseries] = []
+    api_status: dict[str, dict[str, float]] = {}
+
     # API í‚¤ ë¡œë“œ
     stormglass_key = os.getenv('STORMGLASS_API_KEY', '')
     worldtides_key = os.getenv('WORLDTIDES_API_KEY', '')
-    
+
     # 1. Stormglass ë°ì´í„° ìˆ˜ì§‘
     try:
         if stormglass_key:
             sg_connector = StormglassConnector(api_key=stormglass_key)
             sg_timeseries = sg_connector.get_marine_weather(lat, lon, now, end_date, location=location_name)
             all_timeseries.append(sg_timeseries)
             api_status['STORMGLASS'] = {
                 'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
                 'confidence': getattr(sg_timeseries, 'confidence', 0.5)
             }
             print(f"âœ… Stormglass: {len(sg_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
         else:
             api_status['STORMGLASS'] = {'status': 'âŒ API í‚¤ ì—†ìŒ', 'confidence': 0.0}
             print("âŒ Stormglass API í‚¤ ì—†ìŒ")
     except Exception as e:
         print(f"âŒ Stormglass ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
         api_status['STORMGLASS'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}
-    
+
     # 2. Open-Meteo ë°ì´í„° ìˆ˜ì§‘
     try:
         om_connector = OpenMeteoConnector()
         om_timeseries = om_connector.get_marine_weather(lat, lon, now, end_date, location=location_name)
         all_timeseries.append(om_timeseries)
         api_status['OPEN_METEO'] = {
             'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
             'confidence': getattr(om_timeseries, 'confidence', 0.5)
         }
         print(f"âœ… Open-Meteo: {len(om_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
     except Exception as e:
         print(f"âŒ Open-Meteo ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
         api_status['OPEN_METEO'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}
-    
+
     # 3. NCM Selenium ë°ì´í„° ìˆ˜ì§‘
-    try:
-        ncm_ingestor = NCMSeleniumIngestor(headless=True)
-        ncm_timeseries = ncm_ingestor.create_marine_timeseries(location=location_name, forecast_hours=forecast_hours)
-        all_timeseries.append(ncm_timeseries)
-        api_status['NCM_SELENIUM'] = {
-            'status': 'âœ… ì‹¤ì œ ë°ì´í„°' if "fallback" not in ncm_timeseries.source else 'âš ï¸ í´ë°± ë°ì´í„°', 
-            'confidence': getattr(ncm_timeseries, 'confidence', 0.5)
-        }
-        print(f"âœ… NCM Selenium: {len(ncm_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
-    except Exception as e:
-        print(f"âŒ NCM Selenium ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
-        api_status['NCM_SELENIUM'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}
-    
+    if NCMSeleniumIngestor is None:
+        api_status['NCM_SELENIUM'] = {'status': 'âŒ ëª¨ë“ˆ ëˆ„ë½', 'confidence': 0.0}
+        if NCM_IMPORT_ERROR is not None:
+            print(f"âŒ NCM Selenium ë¡œë“œ ì‹¤íŒ¨: {NCM_IMPORT_ERROR}")
+    else:
+        try:
+            ncm_ingestor = NCMSeleniumIngestor(headless=True)
+            ncm_timeseries = ncm_ingestor.create_marine_timeseries(location=location_name, forecast_hours=forecast_hours)
+            all_timeseries.append(ncm_timeseries)
+            api_status['NCM_SELENIUM'] = {
+                'status': 'âœ… ì‹¤ì œ ë°ì´í„°' if "fallback" not in ncm_timeseries.source else 'âš ï¸ í´ë°± ë°ì´í„°',
+                'confidence': getattr(ncm_timeseries, 'confidence', 0.5)
+            }
+            print(f"âœ… NCM Selenium: {len(ncm_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
+        except Exception as e:
+            print(f"âŒ NCM Selenium ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
+            api_status['NCM_SELENIUM'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}
+
     # 4. WorldTides ë°ì´í„° ìˆ˜ì§‘ (ì„ íƒì‚¬í•­)
     if worldtides_key:
         try:
             wt_timeseries = create_marine_timeseries_from_worldtides(lat, lon, worldtides_key, forecast_hours, location_name)
             all_timeseries.append(wt_timeseries)
             api_status['WORLDTIDES'] = {
                 'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
                 'confidence': getattr(wt_timeseries, 'confidence', 0.5)
             }
             print(f"âœ… WorldTides: {len(wt_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
         except Exception as e:
             print(f"âš ï¸ WorldTides ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
             api_status['WORLDTIDES'] = {'status': 'âš ï¸ í¬ë ˆë”§ ë¶€ì¡±', 'confidence': 0.3}
     else:
         api_status['WORLDTIDES'] = {'status': 'âŒ API í‚¤ ì—†ìŒ', 'confidence': 0.0}
-    
+
+    if not all_timeseries:
+        print("âš ï¸ ì™¸ë¶€ ë°ì´í„°ê°€ ì—†ì–´ í•©ì„± ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
+        synthetic_series, synthetic_status = generate_offline_dataset(location_name, forecast_hours)
+        all_timeseries.extend(synthetic_series)
+        api_status.update(synthetic_status)
+        offline_reasons.append("ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
+        resolved_mode = "offline"
+
     return {
         'timeseries': all_timeseries,
         'api_status': api_status,
         'location': location_name,
         'forecast_hours': forecast_hours,
-        'collected_at': now.isoformat()
+        'collected_at': now.isoformat(),
+        'mode': resolved_mode,
+        'offline_reasons': offline_reasons,
     }
 
 def analyze_weather_data(data: dict) -> dict:
     """ìˆ˜ì§‘ëœ ë‚ ì”¨ ë°ì´í„° ë¶„ì„"""
     print("ğŸ“Š ë‚ ì”¨ ë°ì´í„° ë¶„ì„ ì¤‘...")
     
     all_timeseries = data['timeseries']
     if not all_timeseries:
         return {'error': 'ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
     
     # ERI ê³„ì‚°
     eri_calculator = ERICalculator()
     all_eri_points = []
     
     for timeseries in all_timeseries:
         eri_points = eri_calculator.compute_eri_timeseries(timeseries)
         all_eri_points.extend(eri_points)
     
     # ì˜ˆë³´ ìœµí•©
     fusion_settings = {
         'ncm_weight': 0.60,
         'system_weight': 0.40,
         'alpha': 0.7,
         'beta': 0.3
     }
@@ -179,151 +221,164 @@ def analyze_weather_data(data: dict) -> dict:
         'decisions': {
             'total': len(decisions),
             'GO': go_count,
             'CONDITIONAL': conditional_count,
             'NO-GO': no_go_count
         },
         'averages': {
             'eri': avg_eri,
             'wind_speed_ms': avg_wind_speed,
             'wave_height_m': avg_wave_height
         },
         'eri_points': len(all_eri_points),
         'confidence_scores': [getattr(ts, 'confidence', 0.5) for ts in all_timeseries]
     }
 
 def generate_summary_report(data: dict, analysis: dict, output_dir: str) -> dict:
     """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
     print("ğŸ“ ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
     
     output_path = Path(output_dir)
     output_path.mkdir(exist_ok=True)
     
     timestamp = datetime.now().strftime("%Y%m%d_%H%M")
     
     # JSON ìš”ì•½
+    execution_mode = data.get('mode', 'online')
+    success_sources = sum(1 for status in data['api_status'].values() if 'âœ…' in status['status'])
+    total_sources = max(len(data['api_status']), 1)
+    collection_rate = success_sources / total_sources * 100
     summary_json = {
         'metadata': {
             'generated_at': datetime.now().isoformat(),
             'location': data['location'],
             'forecast_hours': data['forecast_hours'],
-            'system_version': 'v2.1'
+            'system_version': 'v2.1',
+            'execution_mode': execution_mode,
         },
         'api_status': data['api_status'],
         'analysis': analysis,
         'collection_stats': {
             'total_timeseries': len(data['timeseries']),
             'total_data_points': analysis.get('total_data_points', 0),
-            'data_collection_rate': len([s for s in data['api_status'].values() if 'âœ…' in s['status']]) / len(data['api_status']) * 100
+            'data_collection_rate': collection_rate,
         }
     }
+
+    if data.get('offline_reasons'):
+        summary_json['metadata']['offline_reasons'] = data['offline_reasons']
     
     json_path = output_path / f"summary_{timestamp}.json"
     with open(json_path, 'w', encoding='utf-8') as f:
         json.dump(summary_json, f, ensure_ascii=False, indent=2)
     
     # CSV ìš”ì•½
     csv_data = []
     for api_name, status in data['api_status'].items():
         csv_data.append({
             'API': api_name,
             'Status': status['status'],
             'Confidence': status['confidence'],
             'Timestamp': datetime.now().isoformat()
         })
     
     csv_path = output_path / f"api_status_{timestamp}.csv"
     df = pd.DataFrame(csv_data)
     df.to_csv(csv_path, index=False, encoding='utf-8')
     
     # í…ìŠ¤íŠ¸ ìš”ì•½
     txt_content = f"""ğŸŒŠ UAE í•´ì—­ í•´ì–‘ ë‚ ì”¨ ë³´ê³ ì„œ
 ========================================
 ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
 ìœ„ì¹˜: {data['location']} (Al Ghallan Island)
 ì˜ˆë³´ ê¸°ê°„: {data['forecast_hours']}ì‹œê°„
-
-ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ í˜„í™©:
+ì‹¤í–‰ ëª¨ë“œ: {execution_mode.upper()}
 """
-    
+
+    if data.get('offline_reasons'):
+        txt_content += "ì˜¤í”„ë¼ì¸ ì‚¬ìœ : " + "; ".join(data['offline_reasons']) + "\n"
+
+    txt_content += "\nğŸ“Š ë°ì´í„° ìˆ˜ì§‘ í˜„í™©:\n"
+
     for api_name, status in data['api_status'].items():
         conf = status.get('confidence', None)
         conf_txt = f"{conf:.2f}" if isinstance(conf, (int, float)) else "N/A"
         txt_content += f"  {api_name}: {status['status']} (ì‹ ë¢°ë„: {conf_txt})\n"
     
     txt_content += f"""
 ğŸ“ˆ ë¶„ì„ ê²°ê³¼:
   - ì´ ë°ì´í„° í¬ì¸íŠ¸: {analysis.get('total_data_points', 0):,}ê°œ
   - ìœµí•© ì˜ˆë³´: {analysis.get('fused_forecasts', 0)}ê°œ
   - í‰ê·  ERI: {analysis.get('averages', {}).get('eri', 0):.3f}
   - í‰ê·  í’ì†: {analysis.get('averages', {}).get('wind_speed_ms', 0):.1f} m/s
   - í‰ê·  íŒŒê³ : {analysis.get('averages', {}).get('wave_height_m', 0):.2f} m
 
 ğŸš¢ ìš´í•­ íŒì •:
   - GO: {analysis.get('decisions', {}).get('GO', 0)}íšŒ
   - CONDITIONAL: {analysis.get('decisions', {}).get('CONDITIONAL', 0)}íšŒ
   - NO-GO: {analysis.get('decisions', {}).get('NO-GO', 0)}íšŒ
 
 ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {json_path.name}
 """
     
     txt_path = output_path / "summary.txt"
     with open(txt_path, 'w', encoding='utf-8') as f:
         f.write(txt_content)
     
     print(f"âœ… ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ:")
     print(f"  - JSON: {json_path}")
     print(f"  - CSV: {csv_path}")
     print(f"  - TXT: {txt_path}")
     
     return {
         'json_path': str(json_path),
         'csv_path': str(csv_path),
         'txt_path': str(txt_path),
         'summary_json': summary_json
     }
 
 def main():
     """ë©”ì¸ í•¨ìˆ˜"""
     parser = argparse.ArgumentParser(description='GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—…')
     parser.add_argument('--config', default='config/locations.yml', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
     parser.add_argument('--out', default='out', help='ì¶œë ¥ ë””ë ‰í„°ë¦¬')
     parser.add_argument('--location', default='AGI', help='ìœ„ì¹˜ ì½”ë“œ')
     parser.add_argument('--hours', type=int, default=24, help='ì˜ˆë³´ ì‹œê°„')
+    parser.add_argument('--mode', choices=['auto', 'online', 'offline'], default='auto', help='ì‹¤í–‰ ëª¨ë“œ (auto/online/offline)')
     
     args = parser.parse_args()
     
     print("ğŸ¤– GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—… ì‹œì‘")
     print("=" * 50)
     
     try:
         # ì„¤ì • ë¡œë“œ
         config = load_config(args.config)
         print(f"âœ… ì„¤ì • ë¡œë“œ: {args.config}")
         
         # ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘
-        data = collect_weather_data(args.location, args.hours)
+        data = collect_weather_data(args.location, args.hours, args.mode)
         
         # ë°ì´í„° ë¶„ì„
         analysis = analyze_weather_data(data)
         
         # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
         report = generate_summary_report(data, analysis, args.out)
         
         # ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰
         try:
             print("\nğŸš¢ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
             from src.marine_ops.operability.api import create_operability_report
             
             # í•­ë¡œ ì •ë³´ ì •ì˜
             routes = [
                 {
                     "name": "Abu Dhabi to AGI or DAS",
                     "distance_nm": 65.0,
                     "planned_speed_kt": 12.0,
                     "hs_forecast": 1.2
                 }
             ]
             
             # ìš´í•­ ê°€ëŠ¥ì„± ë³´ê³ ì„œ ìƒì„±
             # dataëŠ” ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ MarineTimeseries ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
             weather_timeseries = data.get('timeseries', [])

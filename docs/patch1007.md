diff --git a/ncm_web/ncm_selenium_ingestor.py b/ncm_web/ncm_selenium_ingestor.py
index 6153437862d2db4c89e6ded8101c46581bfe4c85..6e0b5302f23cca5874c26d3d712bb0bafacf7ee9 100644
--- a/ncm_web/ncm_selenium_ingestor.py
+++ b/ncm_web/ncm_selenium_ingestor.py
@@ -1,458 +1,550 @@
 # KR: Seleniumì„ ì‚¬ìš©í•œ NCM í•´ì–‘ ê´€ì¸¡ ë°ì´í„° ìˆ˜ì§‘
 # EN: NCM marine observations data collection using Selenium
 
-import time
 import json
-import pandas as pd
+import time
 from datetime import datetime, timedelta
-from typing import List, Dict, Any, Optional
 from pathlib import Path
+from typing import Any, Dict, List, Optional
 
+import pandas as pd
 from selenium import webdriver
+from selenium.webdriver.chrome.options import Options
+from selenium.webdriver.chrome.service import Service
 from selenium.webdriver.common.by import By
-from selenium.webdriver.support.ui import WebDriverWait
 from selenium.webdriver.support import expected_conditions as EC
-from selenium.webdriver.chrome.service import Service
-from selenium.webdriver.chrome.options import Options
+from selenium.webdriver.support.ui import WebDriverWait
 from webdriver_manager.chrome import ChromeDriverManager
 
-from src.marine_ops.core.schema import MarineTimeseries, MarineDataPoint
-from src.marine_ops.core.units import normalize_to_si, calculate_sea_state
+from src.marine_ops.core.schema import MarineDataPoint, MarineTimeseries
+from src.marine_ops.core.units import calculate_sea_state, normalize_to_si
+
 
 class NCMSeleniumIngestor:
     """Seleniumì„ ì‚¬ìš©í•œ NCM í•´ì–‘ ê´€ì¸¡ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
-    
+
     def __init__(self, headless: bool = True):
         self.headless = headless
         self.driver = None
         self.base_url = "https://albahar.ncm.gov.ae"
-    
+
     def _setup_driver(self):
         """Chrome ë“œë¼ì´ë²„ ì„¤ì •"""
         chrome_options = Options()
-        
+
         if self.headless:
             chrome_options.add_argument("--headless")
-        
+
         chrome_options.add_argument("--no-sandbox")
         chrome_options.add_argument("--disable-dev-shm-usage")
         chrome_options.add_argument("--disable-gpu")
         chrome_options.add_argument("--window-size=1920,1080")
-        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
-        
+        chrome_options.add_argument(
+            "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
+        )
+
         # ChromeDriver ìë™ ì„¤ì¹˜ ë° ì„¤ì •
         service = Service(ChromeDriverManager().install())
         self.driver = webdriver.Chrome(service=service, options=chrome_options)
         self.driver.implicitly_wait(10)
-    
+
     def create_marine_timeseries(
-        self, 
-        location: str = "AGI",
-        forecast_hours: int = 72
+        self, location: str = "AGI", forecast_hours: int = 72
     ) -> MarineTimeseries:
         """NCMì—ì„œ í•´ì–‘ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±"""
-        
+
         try:
             self._setup_driver()
-            
+
             # NCM Al Bahar í•´ì–‘ ê´€ì¸¡ í˜ì´ì§€ ì ‘ê·¼
             marine_url = f"{self.base_url}/marine-observations?lang=en"
             print(f"[SELENIUM] ì ‘ê·¼ ì¤‘: {marine_url}")
-            
+
             self.driver.get(marine_url)
-            
+
             # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° (DOMContentLoaded)
             WebDriverWait(self.driver, 30).until(
                 EC.presence_of_element_located((By.TAG_NAME, "body"))
             )
-            
+
             print(f"[SELENIUM] í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
-            
+
             # JavaScript ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸° (load state)
             self.driver.execute_script("return document.readyState") == "complete"
-            
+
             # í•´ì–‘ ê´€ì¸¡ ë°ì´í„° íŒ¨ë„ ëŒ€ê¸°
             try:
                 WebDriverWait(self.driver, 8).until(
-                    EC.presence_of_element_located((By.XPATH, "//*[contains(text(), 'Forecast') or contains(text(), 'Marine') or contains(text(), 'Sea state')]"))
+                    EC.presence_of_element_located(
+                        (
+                            By.XPATH,
+                            "//*[contains(text(), 'Forecast') or contains(text(), 'Marine') or contains(text(), 'Sea state')]",
+                        )
+                    )
                 )
             except Exception:
                 print("[SELENIUM] í•´ì–‘ ë°ì´í„° íŒ¨ë„ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼, ê³„ì† ì§„í–‰")
                 pass
-            
+
             # í…Œì´ë¸”ì´ë‚˜ ë°ì´í„° ì»¨í…Œì´ë„ˆ ì°¾ê¸°
             data_points = self._extract_data_with_selenium(location)
-            
+
             # ë™ì  ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
             if not data_points:
                 print("[SELENIUM] í…Œì´ë¸” ë°ì´í„° ì—†ìŒ, í´ë°± ë°ì´í„° ìƒì„±")
                 data_points = self._create_fallback_data(location, forecast_hours)
-            
+
             return MarineTimeseries(
                 source="ncm_selenium",
                 location=location,
                 data_points=data_points,
                 ingested_at=datetime.now().isoformat(),
-                confidence=0.7
+                confidence=0.7,
             )
-        
+
         except Exception as e:
             print(f"[SELENIUM] ì›¹ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
             # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
-            return self._create_fallback_data(location, forecast_hours)
-        
+            fallback_points = self._create_fallback_data(location, forecast_hours)
+            return MarineTimeseries(
+                source="ncm_selenium_fallback",
+                location=location,
+                data_points=fallback_points,
+                ingested_at=datetime.now().isoformat(),
+                confidence=0.3,
+            )
+
         finally:
             if self.driver:
                 self.driver.quit()
-    
+
     def _extract_data_with_selenium(self, location: str) -> List[MarineDataPoint]:
         """Seleniumìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ"""
         data_points = []
-        
+
         try:
             # í…Œì´ë¸” ìš”ì†Œë“¤ ì°¾ê¸°
             tables = self.driver.find_elements(By.TAG_NAME, "table")
             print(f"[SELENIUM] ë°œê²¬ëœ í…Œì´ë¸” ìˆ˜: {len(tables)}")
-            
+
             for i, table in enumerate(tables):
                 try:
                     print(f"[SELENIUM] í…Œì´ë¸” {i+1} íŒŒì‹± ì¤‘...")
-                    
+
                     # í…Œì´ë¸” HTMLì„ BeautifulSoupìœ¼ë¡œ íŒŒì‹±
                     from bs4 import BeautifulSoup
-                    table_html = table.get_attribute('outerHTML')
-                    soup = BeautifulSoup(table_html, 'html.parser')
-                    
+
+                    table_html = table.get_attribute("outerHTML")
+                    soup = BeautifulSoup(table_html, "html.parser")
+
                     # pandasë¡œ í…Œì´ë¸” íŒŒì‹±
                     df_list = pd.read_html(str(soup))
                     if not df_list:
                         continue
-                    
+
                     df = df_list[0]
                     print(f"[SELENIUM] í…Œì´ë¸” {i+1} ì»¬ëŸ¼: {list(df.columns)}")
                     print(f"[SELENIUM] í…Œì´ë¸” {i+1} í–‰ ìˆ˜: {len(df)}")
-                    
+
                     # ì»¬ëŸ¼ëª… ì •ê·œí™”
-                    df.columns = [str(c).strip().lower().replace(" ", "_").replace("-", "_") for c in df.columns]
-                    
+                    df.columns = [
+                        str(c).strip().lower().replace(" ", "_").replace("-", "_")
+                        for c in df.columns
+                    ]
+
                     # í•´ì–‘ ê´€ì¸¡ ë°ì´í„° íŒŒì‹±
                     for _, row in df.iterrows():
                         data_point = self._parse_observation_row(row, location)
                         if data_point:
                             data_points.append(data_point)
-                
+
                 except Exception as e:
                     print(f"[SELENIUM] í…Œì´ë¸” {i+1} íŒŒì‹± ì˜¤ë¥˜: {e}")
                     continue
-            
+
             # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ë°ì´í„° ì»¨í…Œì´ë„ˆ ì°¾ê¸°
             if not data_points:
                 data_points = self._extract_from_other_containers(location)
-            
+
             print(f"[SELENIUM] ì´ íŒŒì‹±ëœ ë°ì´í„° í¬ì¸íŠ¸: {len(data_points)}ê°œ")
             return data_points
-        
+
         except Exception as e:
             print(f"[SELENIUM] ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
             return []
-    
+
     def _extract_from_other_containers(self, location: str) -> List[MarineDataPoint]:
         """ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
         data_points = []
-        
+
         try:
             # divë‚˜ span ìš”ì†Œì—ì„œ ë°ì´í„° ì°¾ê¸°
-            data_elements = self.driver.find_elements(By.CSS_SELECTOR, 
+            data_elements = self.driver.find_elements(
+                By.CSS_SELECTOR,
                 "div[class*='data'], div[class*='observation'], div[class*='marine'], "
                 "span[class*='data'], span[class*='observation'], "
-                ".weather-data, .marine-data, .observation-data"
+                ".weather-data, .marine-data, .observation-data",
             )
-            
+
             print(f"[SELENIUM] ë°ì´í„° ì»¨í…Œì´ë„ˆ ìˆ˜: {len(data_elements)}")
-            
+
             for element in data_elements:
                 try:
                     text = element.text.strip()
-                    if text and any(keyword in text.lower() for keyword in ['wind', 'wave', 'temp', 'visibility']):
+                    if text and any(
+                        keyword in text.lower()
+                        for keyword in ["wind", "wave", "temp", "visibility"]
+                    ):
                         print(f"[SELENIUM] ë°œê²¬ëœ ë°ì´í„°: {text[:100]}...")
-                        
+
                         # ê°„ë‹¨í•œ ë°ì´í„° íŒŒì‹± ì‹œë„
                         data_point = self._parse_text_data(text, location)
                         if data_point:
                             data_points.append(data_point)
-                
+
                 except Exception as e:
                     continue
-            
+
             return data_points
-        
+
         except Exception as e:
             print(f"[SELENIUM] ì»¨í…Œì´ë„ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
             return []
-    
+
     def _parse_text_data(self, text: str, location: str) -> Optional[MarineDataPoint]:
         """í…ìŠ¤íŠ¸ì—ì„œ í•´ì–‘ ë°ì´í„° íŒŒì‹±"""
         try:
             import re
-            
+
             # ì‹œê°„ ì •ë³´ ì°¾ê¸°
-            time_pattern = r'(\d{1,2}):(\d{2})'
+            time_pattern = r"(\d{1,2}):(\d{2})"
             time_match = re.search(time_pattern, text)
             if time_match:
                 hour, minute = time_match.groups()
-                timestamp = datetime.now().replace(hour=int(hour), minute=int(minute), second=0, microsecond=0).isoformat()
+                timestamp = (
+                    datetime.now()
+                    .replace(
+                        hour=int(hour), minute=int(minute), second=0, microsecond=0
+                    )
+                    .isoformat()
+                )
             else:
                 timestamp = datetime.now().isoformat()
-            
+
             # í’ì† ì°¾ê¸°
-            wind_pattern = r'wind[:\s]*(\d+(?:\.\d+)?)\s*(?:kt|m/s|mph)'
+            wind_pattern = r"wind[:\s]*(\d+(?:\.\d+)?)\s*(?:kt|m/s|mph)"
             wind_match = re.search(wind_pattern, text.lower())
             wind_speed = float(wind_match.group(1)) if wind_match else 0.0
-            
+
             # íŒŒê³  ì°¾ê¸°
-            wave_pattern = r'wave[:\s]*(\d+(?:\.\d+)?)\s*(?:m|ft)'
+            wave_pattern = r"wave[:\s]*(\d+(?:\.\d+)?)\s*(?:m|ft)"
             wave_match = re.search(wave_pattern, text.lower())
             wave_height = float(wave_match.group(1)) if wave_match else 0.0
-            
+
             # ì‹œì • ì°¾ê¸°
-            vis_pattern = r'vis[ibility]*[:\s]*(\d+(?:\.\d+)?)\s*(?:km|miles)'
+            vis_pattern = r"vis[ibility]*[:\s]*(\d+(?:\.\d+)?)\s*(?:km|miles)"
             vis_match = re.search(vis_pattern, text.lower())
             visibility = float(vis_match.group(1)) if vis_match else 10.0
-            
+
             if wind_speed > 0 or wave_height > 0:
                 return MarineDataPoint(
                     timestamp=timestamp,
                     wind_speed=wind_speed,
                     wind_direction=0.0,
                     wave_height=wave_height,
                     visibility=visibility,
-                    sea_state=calculate_sea_state(wave_height) if wave_height > 0 else "Unknown",
-                    confidence=0.70  # NCM Selenium ìŠ¤í¬ë˜í•‘ ì‹ ë¢°ë„
+                    sea_state=(
+                        calculate_sea_state(wave_height)
+                        if wave_height > 0
+                        else "Unknown"
+                    ),
+                    confidence=0.70,  # NCM Selenium ìŠ¤í¬ë˜í•‘ ì‹ ë¢°ë„
                 )
-        
+
         except Exception as e:
             print(f"[SELENIUM] í…ìŠ¤íŠ¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
-        
+
         return None
-    
-    def _parse_observation_row(self, row: pd.Series, location: str) -> Optional[MarineDataPoint]:
+
+    def _parse_observation_row(
+        self, row: pd.Series, location: str
+    ) -> Optional[MarineDataPoint]:
         """ê´€ì¸¡ ë°ì´í„° í–‰ íŒŒì‹±"""
         try:
             # ì‹œê°„ ì •ë³´ ì¶”ì¶œ
             timestamp = self._extract_observation_timestamp(row)
             if not timestamp:
                 return None
-            
+
             # í•´ì–‘ ë°ì´í„° ì¶”ì¶œ
             wind_speed = self._extract_observation_wind_speed(row)
             wind_direction = self._extract_observation_wind_direction(row)
             wave_height = self._extract_observation_wave_height(row)
             visibility = self._extract_observation_visibility(row)
             temperature = self._extract_observation_temperature(row)
-            
+
             # ë°”ë‹¤ ìƒíƒœ ê³„ì‚°
             sea_state = calculate_sea_state(wave_height) if wave_height else "Unknown"
-            
+
             return MarineDataPoint(
                 timestamp=timestamp,
                 wind_speed=wind_speed,
                 wind_direction=wind_direction,
                 wave_height=wave_height,
                 visibility=visibility,
                 temperature=temperature,
-                sea_state=sea_state
+                sea_state=sea_state,
             )
-        
+
         except Exception as e:
             print(f"[SELENIUM] í–‰ íŒŒì‹± ì˜¤ë¥˜: {e}")
             return None
-    
-    def _create_fallback_data(self, location: str, forecast_hours: int) -> List[MarineDataPoint]:
+
+    def _create_fallback_data(
+        self, location: str, forecast_hours: int
+    ) -> List[MarineDataPoint]:
         """í´ë°± ë°ì´í„° ìƒì„± (ì‹¤ì œ ë°ì´í„° ì—†ì„ ë•Œ)"""
         data_points = []
         now = datetime.now()
-        
+
         # 24ì‹œê°„ ì˜ˆë³´ ìƒì„±
         for i in range(min(forecast_hours, 24)):
             timestamp = (now + timedelta(hours=i)).isoformat()
-            
+
             # ì‹œë®¬ë ˆì´ì…˜ëœ í•´ì–‘ ì¡°ê±´
             wind_speed = 8.0 + (i % 8) * 2.0  # 8-22 m/s
             wave_height = 1.0 + (i % 6) * 0.3  # 1.0-2.5 m
-            
+
             data_point = MarineDataPoint(
                 timestamp=timestamp,
                 wind_speed=wind_speed,
                 wind_direction=270.0 + (i * 15) % 360,  # íšŒì „í•˜ëŠ” í’í–¥
                 wave_height=wave_height,
                 sea_state=calculate_sea_state(wave_height),
                 visibility=10.0,
-                confidence=0.30  # í´ë°± ë°ì´í„° ì‹ ë¢°ë„
+                confidence=0.30,  # í´ë°± ë°ì´í„° ì‹ ë¢°ë„
             )
             data_points.append(data_point)
-        
+
         return data_points
-    
+
     # ê¸°ì¡´ ì¶”ì¶œ ë©”ì„œë“œë“¤ ì¬ì‚¬ìš©
     def _extract_observation_timestamp(self, row: pd.Series) -> Optional[str]:
         """ê´€ì¸¡ ë°ì´í„°ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ"""
-        for col in ['time', 'date', 'datetime', 'timestamp', 'observation_time', 'recorded_at']:
+        for col in [
+            "time",
+            "date",
+            "datetime",
+            "timestamp",
+            "observation_time",
+            "recorded_at",
+        ]:
             if col in row and pd.notna(row[col]):
                 try:
                     time_str = str(row[col]).strip()
-                    if 'T' in time_str:
+                    if "T" in time_str:
                         return time_str
-                    elif ':' in time_str and len(time_str) >= 5:  # HH:MM í˜•ì‹
+                    elif ":" in time_str and len(time_str) >= 5:  # HH:MM í˜•ì‹
                         today = datetime.now().date().isoformat()
                         return f"{today}T{time_str}:00"
-                    elif len(time_str) == 4 and time_str.replace(':', '').isdigit():  # HHMM í˜•ì‹
+                    elif (
+                        len(time_str) == 4 and time_str.replace(":", "").isdigit()
+                    ):  # HHMM í˜•ì‹
                         hour = time_str[:2]
                         minute = time_str[2:]
                         today = datetime.now().date().isoformat()
                         return f"{today}T{hour}:{minute}:00"
                 except:
                     continue
         return None
-    
+
     def _extract_observation_wind_speed(self, row: pd.Series) -> float:
         """ê´€ì¸¡ ë°ì´í„°ì—ì„œ í’ì† ì¶”ì¶œ"""
-        for col in ['wind_speed', 'wind', 'speed', 'windspeed', 'wind_velocity', 'ws']:
+        for col in ["wind_speed", "wind", "speed", "windspeed", "wind_velocity", "ws"]:
             if col in row and pd.notna(row[col]):
                 try:
                     value = str(row[col]).strip()
                     # ë‹¨ìœ„ ì œê±° ë° ìˆ«ì ì¶”ì¶œ
-                    value = value.replace('kt', '').replace('m/s', '').replace('mph', '').replace('km/h', '').strip()
+                    value = (
+                        value.replace("kt", "")
+                        .replace("m/s", "")
+                        .replace("mph", "")
+                        .replace("km/h", "")
+                        .strip()
+                    )
                     # ìˆ«ìë§Œ ì¶”ì¶œ
                     import re
-                    numbers = re.findall(r'\d+\.?\d*', value)
+
+                    numbers = re.findall(r"\d+\.?\d*", value)
                     if numbers:
                         speed = float(numbers[0])
                         # ë…¸íŠ¸ë¥¼ m/së¡œ ë³€í™˜ (ì¼ë°˜ì ìœ¼ë¡œ NCMì€ ë…¸íŠ¸ ì‚¬ìš©)
-                        if 'kt' in str(row[col]).lower() or speed > 50:  # ë…¸íŠ¸ë¡œ ì¶”ì •
+                        if "kt" in str(row[col]).lower() or speed > 50:  # ë…¸íŠ¸ë¡œ ì¶”ì •
                             return speed * 0.514444  # kt to m/s
                         return speed
                 except:
                     continue
         return 0.0
-    
+
     def _extract_observation_wind_direction(self, row: pd.Series) -> float:
         """ê´€ì¸¡ ë°ì´í„°ì—ì„œ í’í–¥ ì¶”ì¶œ"""
-        for col in ['wind_direction', 'direction', 'wind_dir', 'wd', 'bearing']:
+        for col in ["wind_direction", "direction", "wind_dir", "wd", "bearing"]:
             if col in row and pd.notna(row[col]):
                 try:
                     value = str(row[col]).strip()
                     # ìˆ«ìë§Œ ì¶”ì¶œ
                     import re
-                    numbers = re.findall(r'\d+\.?\d*', value)
+
+                    numbers = re.findall(r"\d+\.?\d*", value)
                     if numbers:
                         return float(numbers[0])
                     # ë°©í–¥ëª…ì„ ê°ë„ë¡œ ë³€í™˜
                     direction_map = {
-                        'N': 0, 'NNE': 22.5, 'NE': 45, 'ENE': 67.5,
-                        'E': 90, 'ESE': 112.5, 'SE': 135, 'SSE': 157.5,
-                        'S': 180, 'SSW': 202.5, 'SW': 225, 'WSW': 247.5,
-                        'W': 270, 'WNW': 292.5, 'NW': 315, 'NNW': 337.5
+                        "N": 0,
+                        "NNE": 22.5,
+                        "NE": 45,
+                        "ENE": 67.5,
+                        "E": 90,
+                        "ESE": 112.5,
+                        "SE": 135,
+                        "SSE": 157.5,
+                        "S": 180,
+                        "SSW": 202.5,
+                        "SW": 225,
+                        "WSW": 247.5,
+                        "W": 270,
+                        "WNW": 292.5,
+                        "NW": 315,
+                        "NNW": 337.5,
                     }
                     if value.upper() in direction_map:
                         return direction_map[value.upper()]
                 except:
                     continue
         return 0.0
-    
+
     def _extract_observation_wave_height(self, row: pd.Series) -> float:
         """ê´€ì¸¡ ë°ì´í„°ì—ì„œ íŒŒê³  ì¶”ì¶œ"""
-        for col in ['wave_height', 'wave', 'height', 'hs', 'significant_wave_height', 'swell']:
+        for col in [
+            "wave_height",
+            "wave",
+            "height",
+            "hs",
+            "significant_wave_height",
+            "swell",
+        ]:
             if col in row and pd.notna(row[col]):
                 try:
                     value = str(row[col]).strip()
                     # ë‹¨ìœ„ ì œê±° ë° ìˆ«ì ì¶”ì¶œ
-                    value = value.replace('m', '').replace('ft', '').replace('feet', '').strip()
+                    value = (
+                        value.replace("m", "")
+                        .replace("ft", "")
+                        .replace("feet", "")
+                        .strip()
+                    )
                     import re
-                    numbers = re.findall(r'\d+\.?\d*', value)
+
+                    numbers = re.findall(r"\d+\.?\d*", value)
                     if numbers:
                         height = float(numbers[0])
                         # í”¼íŠ¸ë¥¼ ë¯¸í„°ë¡œ ë³€í™˜
-                        if 'ft' in str(row[col]).lower() or height > 10:  # í”¼íŠ¸ë¡œ ì¶”ì •
+                        if "ft" in str(row[col]).lower() or height > 10:  # í”¼íŠ¸ë¡œ ì¶”ì •
                             return height * 0.3048  # ft to m
                         return height
                 except:
                     continue
         return 0.0
-    
+
     def _extract_observation_visibility(self, row: pd.Series) -> float:
         """ê´€ì¸¡ ë°ì´í„°ì—ì„œ ì‹œì • ì¶”ì¶œ"""
-        for col in ['visibility', 'vis', 'sight', 'visual_range']:
+        for col in ["visibility", "vis", "sight", "visual_range"]:
             if col in row and pd.notna(row[col]):
                 try:
                     value = str(row[col]).strip()
-                    value = value.replace('km', '').replace('miles', '').strip()
+                    value = value.replace("km", "").replace("miles", "").strip()
                     import re
-                    numbers = re.findall(r'\d+\.?\d*', value)
+
+                    numbers = re.findall(r"\d+\.?\d*", value)
                     if numbers:
                         vis = float(numbers[0])
                         # ë§ˆì¼ì„ kmë¡œ ë³€í™˜
-                        if 'miles' in str(row[col]).lower() or vis > 50:  # ë§ˆì¼ë¡œ ì¶”ì •
+                        if "miles" in str(row[col]).lower() or vis > 50:  # ë§ˆì¼ë¡œ ì¶”ì •
                             return vis * 1.60934  # miles to km
                         return vis
                 except:
                     continue
         return 10.0  # ê¸°ë³¸ê°’
-    
+
     def _extract_observation_temperature(self, row: pd.Series) -> float:
         """ê´€ì¸¡ ë°ì´í„°ì—ì„œ ì˜¨ë„ ì¶”ì¶œ"""
-        for col in ['temperature', 'temp', 'air_temp', 'air_temperature']:
+        for col in ["temperature", "temp", "air_temp", "air_temperature"]:
             if col in row and pd.notna(row[col]):
                 try:
                     value = str(row[col]).strip()
-                    value = value.replace('Â°C', '').replace('Â°F', '').replace('C', '').replace('F', '').strip()
+                    value = (
+                        value.replace("Â°C", "")
+                        .replace("Â°F", "")
+                        .replace("C", "")
+                        .replace("F", "")
+                        .strip()
+                    )
                     import re
-                    numbers = re.findall(r'-?\d+\.?\d*', value)
+
+                    numbers = re.findall(r"-?\d+\.?\d*", value)
                     if numbers:
                         temp = float(numbers[0])
                         # í™”ì”¨ë¥¼ ì„­ì”¨ë¡œ ë³€í™˜
-                        if 'F' in str(row[col]).upper() or temp > 50:  # í™”ì”¨ë¡œ ì¶”ì •
-                            return (temp - 32) * 5/9  # F to C
+                        if "F" in str(row[col]).upper() or temp > 50:  # í™”ì”¨ë¡œ ì¶”ì •
+                            return (temp - 32) * 5 / 9  # F to C
                         return temp
                 except:
                     continue
         return None
 
+
 def save_ncm_selenium_forecast(location: str, timeseries: MarineTimeseries) -> None:
     """NCM Selenium ì˜ˆë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
     output_dir = Path("out")
     output_dir.mkdir(exist_ok=True)
-    
+
     filename = f"ncm_selenium_{location}.json"
     output_path = output_dir / filename
-    
-    with open(output_path, 'w', encoding='utf-8') as f:
-        json.dump({
-            'source': timeseries.source,
-            'location': timeseries.location,
-            'ingested_at': timeseries.ingested_at,
-            'confidence': timeseries.confidence,
-            'data_points': [
-                {
-                    'timestamp': dp.timestamp,
-                    'wind_speed': dp.wind_speed,
-                    'wind_direction': dp.wind_direction,
-                    'wave_height': dp.wave_height,
-                    'visibility': dp.visibility,
-                    'temperature': dp.temperature,
-                    'sea_state': dp.sea_state
-                }
-                for dp in timeseries.data_points
-            ]
-        }, f, ensure_ascii=False, indent=2)
-    
+
+    with open(output_path, "w", encoding="utf-8") as f:
+        json.dump(
+            {
+                "source": timeseries.source,
+                "location": timeseries.location,
+                "ingested_at": timeseries.ingested_at,
+                "confidence": timeseries.confidence,
+                "data_points": [
+                    {
+                        "timestamp": dp.timestamp,
+                        "wind_speed": dp.wind_speed,
+                        "wind_direction": dp.wind_direction,
+                        "wave_height": dp.wave_height,
+                        "visibility": dp.visibility,
+                        "temperature": dp.temperature,
+                        "sea_state": dp.sea_state,
+                    }
+                    for dp in timeseries.data_points
+                ],
+            },
+            f,
+            ensure_ascii=False,
+            indent=2,
+        )
+
     print(f"NCM Selenium ì˜ˆë³´ ì €ì¥ë¨: {output_path}")
 
+
 if __name__ == "__main__":
     # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
     ingestor = NCMSeleniumIngestor(headless=True)
-    
+
     for location in ["AGI", "DAS"]:
         print(f"\n=== {location} ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ===")
         timeseries = ingestor.create_marine_timeseries(location)
         save_ncm_selenium_forecast(location, timeseries)
         print(f"ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜: {len(timeseries.data_points)}")
diff --git a/scripts/weather_job.py b/scripts/weather_job.py
index 27b12faf118ed05277a848f71abc0a1268f8afde..7abdd6987629c2a0a39bc40e40c8c30ca8c283f9 100644
--- a/scripts/weather_job.py
+++ b/scripts/weather_job.py
@@ -1,385 +1,585 @@
 #!/usr/bin/env python3
 """
 GitHub Actionsìš© í•´ì–‘ ë‚ ì”¨ ì‘ì—… ìŠ¤í¬ë¦½íŠ¸
 ë§¤ì‹œê°„ ì‹¤í–‰ë˜ì–´ í•´ì–‘ ë‚ ì”¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
 """
 
+import argparse
+import json
+import math
 import os
 import sys
-import json
-import argparse
+from datetime import datetime, timedelta, timezone
 from pathlib import Path
-from datetime import datetime, timedelta
+from typing import List, Tuple
+
 import pandas as pd
 
 # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
 project_root = Path(__file__).parent.parent
 sys.path.insert(0, str(project_root))
 
-from src.marine_ops.connectors.stormglass import StormglassConnector, LOCATIONS as SG_LOCATIONS
-from src.marine_ops.connectors.open_meteo import OpenMeteoConnector
-from src.marine_ops.connectors.worldtides import create_marine_timeseries_from_worldtides
 from ncm_web.ncm_selenium_ingestor import NCMSeleniumIngestor
-from src.marine_ops.eri.compute import ERICalculator
+from src.marine_ops.connectors.open_meteo import OpenMeteoConnector
+from src.marine_ops.connectors.stormglass import LOCATIONS as SG_LOCATIONS
+from src.marine_ops.connectors.stormglass import StormglassConnector
+from src.marine_ops.connectors.worldtides import (
+    create_marine_timeseries_from_worldtides,
+)
+from src.marine_ops.core.schema import (
+    ERIPoint,
+    MarineDataPoint,
+    MarineTimeseries,
+    OperationalDecision,
+)
 from src.marine_ops.decision.fusion import ForecastFusion, OperationalDecisionMaker
-from src.marine_ops.core.schema import MarineTimeseries, MarineDataPoint, OperationalDecision, ERIPoint
+from src.marine_ops.eri.compute import ERICalculator
+
+
+def create_mock_timeseries(
+    source_name: str,
+    location: str,
+    forecast_hours: int,
+    base_time: datetime,
+    reason: str,
+    confidence: float = 0.35,
+) -> Tuple[MarineTimeseries, dict]:
+    """ëª¨ì˜ í•´ì–‘ ì‹œê³„ì—´ ìƒì„± / Generate mock marine timeseries."""
+
+    data_points: List[MarineDataPoint] = []
+    for hour_index in range(max(forecast_hours, 12)):
+        timestamp = base_time + timedelta(hours=hour_index)
+        phase = (hour_index % 12) / 12
+        wind_speed = 6.0 + 1.5 * math.sin(math.tau * phase)
+        wave_height = 0.8 + 0.3 * math.cos(math.tau * phase)
+        data_points.append(
+            MarineDataPoint(
+                timestamp=timestamp.isoformat(),
+                wind_speed=round(wind_speed, 2),
+                wind_direction=(90 + hour_index * 15) % 360,
+                wave_height=round(max(wave_height, 0.2), 2),
+                wind_gust=round(wind_speed * 1.2, 2),
+                wave_period=5.0 + 0.5 * math.sin(math.tau * phase),
+                wave_direction=(120 + hour_index * 10) % 360,
+                visibility=9.5,
+                temperature=28.0,
+                humidity=0.68,
+                swell_wave_height=round(max(wave_height - 0.1, 0.15), 2),
+                swell_wave_period=6.0,
+                swell_wave_direction=(150 + hour_index * 12) % 360,
+                wind_wave_height=round(max(wave_height - 0.05, 0.10), 2),
+                wind_wave_period=4.5,
+                wind_wave_direction=(60 + hour_index * 14) % 360,
+                ocean_current_speed=0.35,
+                ocean_current_direction=45.0,
+                sea_surface_temperature=27.5,
+                sea_level=0.2 * math.sin(math.tau * phase),
+                confidence=confidence,
+            )
+        )
+
+    mock_timeseries = MarineTimeseries(
+        source=f"{source_name}_mock",
+        location=location,
+        data_points=data_points,
+        ingested_at=datetime.now(timezone.utc).isoformat(),
+        confidence=confidence,
+    )
+
+    status_payload = {
+        "status": f"âš ï¸ ëª¨ì˜ ë°ì´í„° ({reason})",
+        "confidence": confidence,
+    }
+
+    return mock_timeseries, status_payload
+
 
 def load_config(config_path: str) -> dict:
     """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
     try:
-        with open(config_path, 'r', encoding='utf-8') as f:
-            if config_path.endswith('.yml') or config_path.endswith('.yaml'):
+        with open(config_path, "r", encoding="utf-8") as f:
+            if config_path.endswith(".yml") or config_path.endswith(".yaml"):
                 import yaml
+
                 return yaml.safe_load(f)
             else:
                 return json.load(f)
     except FileNotFoundError:
         print(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
         return {}
 
+
 def collect_weather_data(location_name: str = "AGI", forecast_hours: int = 24) -> dict:
-    """í•´ì–‘ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘"""
+    """í•´ì–‘ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘ / Collect marine weather data."""
     print(f"ğŸŒŠ {location_name} í•´ì—­ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
-    
-    lat, lon = SG_LOCATIONS[location_name]['lat'], SG_LOCATIONS[location_name]['lon']
+
+    lat, lon = SG_LOCATIONS[location_name]["lat"], SG_LOCATIONS[location_name]["lon"]
     now = datetime.now()
     end_date = now + timedelta(hours=forecast_hours)
-    
+
     all_timeseries = []
     api_status = {}
-    
+    resilience_notes: List[str] = []
+
     # API í‚¤ ë¡œë“œ
-    stormglass_key = os.getenv('STORMGLASS_API_KEY', '')
-    worldtides_key = os.getenv('WORLDTIDES_API_KEY', '')
-    
+    stormglass_key = os.getenv("STORMGLASS_API_KEY", "")
+    worldtides_key = os.getenv("WORLDTIDES_API_KEY", "")
+
     # 1. Stormglass ë°ì´í„° ìˆ˜ì§‘
     try:
         if stormglass_key:
             sg_connector = StormglassConnector(api_key=stormglass_key)
-            sg_timeseries = sg_connector.get_marine_weather(lat, lon, now, end_date, location=location_name)
+            sg_timeseries = sg_connector.get_marine_weather(
+                lat, lon, now, end_date, location=location_name
+            )
             all_timeseries.append(sg_timeseries)
-            api_status['STORMGLASS'] = {
-                'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
-                'confidence': getattr(sg_timeseries, 'confidence', 0.5)
+            api_status["STORMGLASS"] = {
+                "status": "âœ… ì‹¤ì œ ë°ì´í„°",
+                "confidence": getattr(sg_timeseries, "confidence", 0.5),
             }
             print(f"âœ… Stormglass: {len(sg_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
         else:
-            api_status['STORMGLASS'] = {'status': 'âŒ API í‚¤ ì—†ìŒ', 'confidence': 0.0}
+            api_status["STORMGLASS"] = {"status": "âŒ API í‚¤ ì—†ìŒ", "confidence": 0.0}
             print("âŒ Stormglass API í‚¤ ì—†ìŒ")
+            mock_ts, status_payload = create_mock_timeseries(
+                "stormglass",
+                location_name,
+                forecast_hours,
+                now,
+                "API í‚¤ ì—†ìŒ",
+            )
+            all_timeseries.append(mock_ts)
+            api_status["STORMGLASS_FALLBACK"] = status_payload
+            resilience_notes.append(
+                "Stormglass ì‹¤ë°ì´í„° ëŒ€ì‹  ëª¨ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
+            )
     except Exception as e:
         print(f"âŒ Stormglass ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
-        api_status['STORMGLASS'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}
-    
+        api_status["STORMGLASS"] = {"status": "âŒ ì‹¤íŒ¨", "confidence": 0.0}
+        mock_ts, status_payload = create_mock_timeseries(
+            "stormglass",
+            location_name,
+            forecast_hours,
+            now,
+            "ìš”ì²­ ì‹¤íŒ¨",
+        )
+        all_timeseries.append(mock_ts)
+        api_status["STORMGLASS_FALLBACK"] = status_payload
+        resilience_notes.append(
+            "Stormglass í˜¸ì¶œ ì‹¤íŒ¨ë¡œ ìë™ ìƒì„± ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
+        )
+
     # 2. Open-Meteo ë°ì´í„° ìˆ˜ì§‘
     try:
         om_connector = OpenMeteoConnector()
-        om_timeseries = om_connector.get_marine_weather(lat, lon, now, end_date, location=location_name)
+        om_timeseries = om_connector.get_marine_weather(
+            lat, lon, now, end_date, location=location_name
+        )
         all_timeseries.append(om_timeseries)
-        api_status['OPEN_METEO'] = {
-            'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
-            'confidence': getattr(om_timeseries, 'confidence', 0.5)
+        api_status["OPEN_METEO"] = {
+            "status": "âœ… ì‹¤ì œ ë°ì´í„°",
+            "confidence": getattr(om_timeseries, "confidence", 0.5),
         }
         print(f"âœ… Open-Meteo: {len(om_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
     except Exception as e:
         print(f"âŒ Open-Meteo ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
-        api_status['OPEN_METEO'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}
-    
+        api_status["OPEN_METEO"] = {"status": "âŒ ì‹¤íŒ¨", "confidence": 0.0}
+        mock_ts, status_payload = create_mock_timeseries(
+            "open_meteo",
+            location_name,
+            forecast_hours,
+            now,
+            "ìš”ì²­ ì‹¤íŒ¨",
+            confidence=0.4,
+        )
+        all_timeseries.append(mock_ts)
+        api_status["OPEN_METEO_FALLBACK"] = status_payload
+        resilience_notes.append("Open-Meteo ì‘ë‹µ ì‹¤íŒ¨ë¡œ ëª¨ì˜ ë°ì´í„°ë¥¼ í•©ì„±í–ˆìŠµë‹ˆë‹¤.")
+
     # 3. NCM Selenium ë°ì´í„° ìˆ˜ì§‘
     try:
         ncm_ingestor = NCMSeleniumIngestor(headless=True)
-        ncm_timeseries = ncm_ingestor.create_marine_timeseries(location=location_name, forecast_hours=forecast_hours)
+        ncm_timeseries = ncm_ingestor.create_marine_timeseries(
+            location=location_name, forecast_hours=forecast_hours
+        )
         all_timeseries.append(ncm_timeseries)
-        api_status['NCM_SELENIUM'] = {
-            'status': 'âœ… ì‹¤ì œ ë°ì´í„°' if "fallback" not in ncm_timeseries.source else 'âš ï¸ í´ë°± ë°ì´í„°', 
-            'confidence': getattr(ncm_timeseries, 'confidence', 0.5)
+        api_status["NCM_SELENIUM"] = {
+            "status": (
+                "âœ… ì‹¤ì œ ë°ì´í„°"
+                if "fallback" not in ncm_timeseries.source
+                else "âš ï¸ í´ë°± ë°ì´í„°"
+            ),
+            "confidence": getattr(ncm_timeseries, "confidence", 0.5),
         }
         print(f"âœ… NCM Selenium: {len(ncm_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
     except Exception as e:
         print(f"âŒ NCM Selenium ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
-        api_status['NCM_SELENIUM'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}
-    
+        api_status["NCM_SELENIUM"] = {"status": "âŒ ì‹¤íŒ¨", "confidence": 0.0}
+        mock_ts, status_payload = create_mock_timeseries(
+            "ncm",
+            location_name,
+            forecast_hours,
+            now,
+            "ì…€ë ˆëŠ„ ì‹¤íŒ¨",
+            confidence=0.3,
+        )
+        all_timeseries.append(mock_ts)
+        api_status["NCM_SELENIUM_FALLBACK"] = status_payload
+        resilience_notes.append("NCM Selenium ëŒ€ì‹  ëª¨ì˜ ìš´í•­ ë°ì´í„°ë¥¼ ì£¼ì…í–ˆìŠµë‹ˆë‹¤.")
+
     # 4. WorldTides ë°ì´í„° ìˆ˜ì§‘ (ì„ íƒì‚¬í•­)
     if worldtides_key:
         try:
-            wt_timeseries = create_marine_timeseries_from_worldtides(lat, lon, worldtides_key, forecast_hours, location_name)
+            wt_timeseries = create_marine_timeseries_from_worldtides(
+                lat, lon, worldtides_key, forecast_hours, location_name
+            )
             all_timeseries.append(wt_timeseries)
-            api_status['WORLDTIDES'] = {
-                'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
-                'confidence': getattr(wt_timeseries, 'confidence', 0.5)
+            api_status["WORLDTIDES"] = {
+                "status": "âœ… ì‹¤ì œ ë°ì´í„°",
+                "confidence": getattr(wt_timeseries, "confidence", 0.5),
             }
             print(f"âœ… WorldTides: {len(wt_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
         except Exception as e:
             print(f"âš ï¸ WorldTides ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
-            api_status['WORLDTIDES'] = {'status': 'âš ï¸ í¬ë ˆë”§ ë¶€ì¡±', 'confidence': 0.3}
+            api_status["WORLDTIDES"] = {"status": "âš ï¸ í¬ë ˆë”§ ë¶€ì¡±", "confidence": 0.3}
+            mock_ts, status_payload = create_mock_timeseries(
+                "worldtides",
+                location_name,
+                forecast_hours,
+                now,
+                "í¬ë ˆë”§ ë¶€ì¡±",
+                confidence=0.32,
+            )
+            all_timeseries.append(mock_ts)
+            api_status["WORLDTIDES_FALLBACK"] = status_payload
+            resilience_notes.append(
+                "WorldTides í¬ë ˆë”§ ë¶€ì¡± ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ê²°í•©í–ˆìŠµë‹ˆë‹¤."
+            )
     else:
-        api_status['WORLDTIDES'] = {'status': 'âŒ API í‚¤ ì—†ìŒ', 'confidence': 0.0}
-    
+        api_status["WORLDTIDES"] = {"status": "âŒ API í‚¤ ì—†ìŒ", "confidence": 0.0}
+        mock_ts, status_payload = create_mock_timeseries(
+            "worldtides",
+            location_name,
+            forecast_hours,
+            now,
+            "API í‚¤ ì—†ìŒ",
+            confidence=0.3,
+        )
+        all_timeseries.append(mock_ts)
+        api_status["WORLDTIDES_FALLBACK"] = status_payload
+        resilience_notes.append(
+            "WorldTides API í‚¤ ë¶€ì¬ ì‹œ ëª¨ì˜ ì¡°ì„ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
+        )
+
     return {
-        'timeseries': all_timeseries,
-        'api_status': api_status,
-        'location': location_name,
-        'forecast_hours': forecast_hours,
-        'collected_at': now.isoformat()
+        "timeseries": all_timeseries,
+        "api_status": api_status,
+        "location": location_name,
+        "forecast_hours": forecast_hours,
+        "collected_at": now.isoformat(),
+        "resilience_notes": resilience_notes,
     }
 
+
 def analyze_weather_data(data: dict) -> dict:
     """ìˆ˜ì§‘ëœ ë‚ ì”¨ ë°ì´í„° ë¶„ì„"""
     print("ğŸ“Š ë‚ ì”¨ ë°ì´í„° ë¶„ì„ ì¤‘...")
-    
-    all_timeseries = data['timeseries']
+
+    all_timeseries = data["timeseries"]
     if not all_timeseries:
-        return {'error': 'ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
-    
+        return {"error": "ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
+
     # ERI ê³„ì‚°
     eri_calculator = ERICalculator()
     all_eri_points = []
-    
+
     for timeseries in all_timeseries:
         eri_points = eri_calculator.compute_eri_timeseries(timeseries)
         all_eri_points.extend(eri_points)
-    
+
     # ì˜ˆë³´ ìœµí•©
     fusion_settings = {
-        'ncm_weight': 0.60,
-        'system_weight': 0.40,
-        'alpha': 0.7,
-        'beta': 0.3
+        "ncm_weight": 0.60,
+        "system_weight": 0.40,
+        "alpha": 0.7,
+        "beta": 0.3,
     }
-    
+
     forecast_fusion = ForecastFusion(fusion_settings)
-    fused_forecasts = forecast_fusion.fuse_forecast_sources(all_timeseries, data['location'])
-    
+    fused_forecasts = forecast_fusion.fuse_forecast_sources(
+        all_timeseries, data["location"]
+    )
+
     # ìš´í•­ íŒì •
     decision_settings = {
-        'gate': {
-            'go': {'hs_m': 1.0, 'wind_kt': 20.0},
-            'conditional': {'hs_m': 1.2, 'wind_kt': 22.0}
+        "gate": {
+            "go": {"hs_m": 1.0, "wind_kt": 20.0},
+            "conditional": {"hs_m": 1.2, "wind_kt": 22.0},
         },
-        'alert_gamma': {
-            'rough_at_times': 0.15,
-            'high_seas': 0.30
-        }
+        "alert_gamma": {"rough_at_times": 0.15, "high_seas": 0.30},
     }
-    
+
     decision_maker = OperationalDecisionMaker(decision_settings)
     decisions = decision_maker.decide_and_eta(fused_forecasts, all_eri_points)
-    
+
     # í†µê³„ ê³„ì‚°
-    go_count = sum(1 for d in decisions if d.decision == 'GO')
-    conditional_count = sum(1 for d in decisions if d.decision == 'CONDITIONAL')
-    no_go_count = sum(1 for d in decisions if d.decision == 'NO-GO')
-    
-    avg_eri = sum(p.eri_value for p in all_eri_points) / len(all_eri_points) if all_eri_points else 0
-    avg_wind_speed = sum(f.wind_speed_fused for f in fused_forecasts) / len(fused_forecasts) if fused_forecasts else 0
-    avg_wave_height = sum(f.wave_height_fused for f in fused_forecasts) / len(fused_forecasts) if fused_forecasts else 0
-    
+    go_count = sum(1 for d in decisions if d.decision == "GO")
+    conditional_count = sum(1 for d in decisions if d.decision == "CONDITIONAL")
+    no_go_count = sum(1 for d in decisions if d.decision == "NO-GO")
+
+    avg_eri = (
+        sum(p.eri_value for p in all_eri_points) / len(all_eri_points)
+        if all_eri_points
+        else 0
+    )
+    avg_wind_speed = (
+        sum(f.wind_speed_fused for f in fused_forecasts) / len(fused_forecasts)
+        if fused_forecasts
+        else 0
+    )
+    avg_wave_height = (
+        sum(f.wave_height_fused for f in fused_forecasts) / len(fused_forecasts)
+        if fused_forecasts
+        else 0
+    )
+
     return {
-        'total_data_points': sum(len(ts.data_points) for ts in all_timeseries),
-        'fused_forecasts': len(fused_forecasts),
-        'decisions': {
-            'total': len(decisions),
-            'GO': go_count,
-            'CONDITIONAL': conditional_count,
-            'NO-GO': no_go_count
+        "total_data_points": sum(len(ts.data_points) for ts in all_timeseries),
+        "fused_forecasts": len(fused_forecasts),
+        "decisions": {
+            "total": len(decisions),
+            "GO": go_count,
+            "CONDITIONAL": conditional_count,
+            "NO-GO": no_go_count,
         },
-        'averages': {
-            'eri': avg_eri,
-            'wind_speed_ms': avg_wind_speed,
-            'wave_height_m': avg_wave_height
+        "averages": {
+            "eri": avg_eri,
+            "wind_speed_ms": avg_wind_speed,
+            "wave_height_m": avg_wave_height,
         },
-        'eri_points': len(all_eri_points),
-        'confidence_scores': [getattr(ts, 'confidence', 0.5) for ts in all_timeseries]
+        "eri_points": len(all_eri_points),
+        "confidence_scores": [getattr(ts, "confidence", 0.5) for ts in all_timeseries],
     }
 
+
 def generate_summary_report(data: dict, analysis: dict, output_dir: str) -> dict:
-    """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
+    """ìš”ì•½ ë³´ê³ ì„œ ìƒì„± / Generate summary report."""
     print("ğŸ“ ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
-    
+
     output_path = Path(output_dir)
     output_path.mkdir(exist_ok=True)
-    
+
     timestamp = datetime.now().strftime("%Y%m%d_%H%M")
-    
+
     # JSON ìš”ì•½
+    resilience_notes = data.get("resilience_notes", [])
+
     summary_json = {
-        'metadata': {
-            'generated_at': datetime.now().isoformat(),
-            'location': data['location'],
-            'forecast_hours': data['forecast_hours'],
-            'system_version': 'v2.1'
+        "metadata": {
+            "generated_at": datetime.now().isoformat(),
+            "location": data["location"],
+            "forecast_hours": data["forecast_hours"],
+            "system_version": "v2.1",
+            "resilience_mode": bool(resilience_notes),
         },
-        'api_status': data['api_status'],
-        'analysis': analysis,
-        'collection_stats': {
-            'total_timeseries': len(data['timeseries']),
-            'total_data_points': analysis.get('total_data_points', 0),
-            'data_collection_rate': len([s for s in data['api_status'].values() if 'âœ…' in s['status']]) / len(data['api_status']) * 100
-        }
+        "api_status": data["api_status"],
+        "analysis": analysis,
+        "collection_stats": {
+            "total_timeseries": len(data["timeseries"]),
+            "total_data_points": analysis.get("total_data_points", 0),
+            "data_collection_rate": len(
+                [s for s in data["api_status"].values() if "âœ…" in s["status"]]
+            )
+            / len(data["api_status"])
+            * 100,
+        },
+        "resilience_notes": resilience_notes,
     }
-    
+
     json_path = output_path / f"summary_{timestamp}.json"
-    with open(json_path, 'w', encoding='utf-8') as f:
+    with open(json_path, "w", encoding="utf-8") as f:
         json.dump(summary_json, f, ensure_ascii=False, indent=2)
-    
+
     # CSV ìš”ì•½
     csv_data = []
-    for api_name, status in data['api_status'].items():
-        csv_data.append({
-            'API': api_name,
-            'Status': status['status'],
-            'Confidence': status['confidence'],
-            'Timestamp': datetime.now().isoformat()
-        })
-    
+    for api_name, status in data["api_status"].items():
+        csv_data.append(
+            {
+                "API": api_name,
+                "Status": status["status"],
+                "Confidence": status["confidence"],
+                "Timestamp": datetime.now().isoformat(),
+            }
+        )
+
     csv_path = output_path / f"api_status_{timestamp}.csv"
     df = pd.DataFrame(csv_data)
-    df.to_csv(csv_path, index=False, encoding='utf-8')
-    
+    df.to_csv(csv_path, index=False, encoding="utf-8")
+
     # í…ìŠ¤íŠ¸ ìš”ì•½
     txt_content = f"""ğŸŒŠ UAE í•´ì—­ í•´ì–‘ ë‚ ì”¨ ë³´ê³ ì„œ
 ========================================
 ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
 ìœ„ì¹˜: {data['location']} (Al Ghallan Island)
 ì˜ˆë³´ ê¸°ê°„: {data['forecast_hours']}ì‹œê°„
 
 ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ í˜„í™©:
 """
-    
-    for api_name, status in data['api_status'].items():
-        conf = status.get('confidence', None)
+
+    for api_name, status in data["api_status"].items():
+        conf = status.get("confidence", None)
         conf_txt = f"{conf:.2f}" if isinstance(conf, (int, float)) else "N/A"
         txt_content += f"  {api_name}: {status['status']} (ì‹ ë¢°ë„: {conf_txt})\n"
-    
+
     txt_content += f"""
 ğŸ“ˆ ë¶„ì„ ê²°ê³¼:
   - ì´ ë°ì´í„° í¬ì¸íŠ¸: {analysis.get('total_data_points', 0):,}ê°œ
   - ìœµí•© ì˜ˆë³´: {analysis.get('fused_forecasts', 0)}ê°œ
   - í‰ê·  ERI: {analysis.get('averages', {}).get('eri', 0):.3f}
   - í‰ê·  í’ì†: {analysis.get('averages', {}).get('wind_speed_ms', 0):.1f} m/s
   - í‰ê·  íŒŒê³ : {analysis.get('averages', {}).get('wave_height_m', 0):.2f} m
 
 ğŸš¢ ìš´í•­ íŒì •:
   - GO: {analysis.get('decisions', {}).get('GO', 0)}íšŒ
   - CONDITIONAL: {analysis.get('decisions', {}).get('CONDITIONAL', 0)}íšŒ
   - NO-GO: {analysis.get('decisions', {}).get('NO-GO', 0)}íšŒ
 
 ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {json_path.name}
 """
-    
+
+    if resilience_notes:
+        txt_content += "\nğŸ›¡ï¸ ì‹œìŠ¤í…œ ì•ˆì •í™” ë©”ëª¨:\n"
+        for note in resilience_notes:
+            txt_content += f"  - {note}\n"
+
     txt_path = output_path / "summary.txt"
-    with open(txt_path, 'w', encoding='utf-8') as f:
+    with open(txt_path, "w", encoding="utf-8") as f:
         f.write(txt_content)
-    
+
     print(f"âœ… ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ:")
     print(f"  - JSON: {json_path}")
     print(f"  - CSV: {csv_path}")
     print(f"  - TXT: {txt_path}")
-    
+
     return {
-        'json_path': str(json_path),
-        'csv_path': str(csv_path),
-        'txt_path': str(txt_path),
-        'summary_json': summary_json
+        "json_path": str(json_path),
+        "csv_path": str(csv_path),
+        "txt_path": str(txt_path),
+        "summary_json": summary_json,
     }
 
+
 def main():
     """ë©”ì¸ í•¨ìˆ˜"""
-    parser = argparse.ArgumentParser(description='GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—…')
-    parser.add_argument('--config', default='config/locations.yml', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
-    parser.add_argument('--out', default='out', help='ì¶œë ¥ ë””ë ‰í„°ë¦¬')
-    parser.add_argument('--location', default='AGI', help='ìœ„ì¹˜ ì½”ë“œ')
-    parser.add_argument('--hours', type=int, default=24, help='ì˜ˆë³´ ì‹œê°„')
-    
+    parser = argparse.ArgumentParser(description="GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—…")
+    parser.add_argument(
+        "--config", default="config/locations.yml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ"
+    )
+    parser.add_argument("--out", default="out", help="ì¶œë ¥ ë””ë ‰í„°ë¦¬")
+    parser.add_argument("--location", default="AGI", help="ìœ„ì¹˜ ì½”ë“œ")
+    parser.add_argument("--hours", type=int, default=24, help="ì˜ˆë³´ ì‹œê°„")
+
     args = parser.parse_args()
-    
+
     print("ğŸ¤– GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—… ì‹œì‘")
     print("=" * 50)
-    
+
     try:
         # ì„¤ì • ë¡œë“œ
         config = load_config(args.config)
         print(f"âœ… ì„¤ì • ë¡œë“œ: {args.config}")
-        
+
         # ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘
         data = collect_weather_data(args.location, args.hours)
-        
+
         # ë°ì´í„° ë¶„ì„
         analysis = analyze_weather_data(data)
-        
+
         # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
         report = generate_summary_report(data, analysis, args.out)
-        
+
         # ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰
         try:
             print("\nğŸš¢ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
             from src.marine_ops.operability.api import create_operability_report
-            
+
             # í•­ë¡œ ì •ë³´ ì •ì˜
             routes = [
                 {
                     "name": "Abu Dhabi to AGI or DAS",
                     "distance_nm": 65.0,
                     "planned_speed_kt": 12.0,
-                    "hs_forecast": 1.2
+                    "hs_forecast": 1.2,
                 }
             ]
-            
+
             # ìš´í•­ ê°€ëŠ¥ì„± ë³´ê³ ì„œ ìƒì„±
             # dataëŠ” ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ MarineTimeseries ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
-            weather_timeseries = data.get('timeseries', [])
-            operability_report = create_operability_report(weather_timeseries, routes, forecast_days=7)
-            
+            weather_timeseries = data.get("timeseries", [])
+            operability_report = create_operability_report(
+                weather_timeseries, routes, forecast_days=7
+            )
+
             # ìš´í•­ ê°€ëŠ¥ì„± ê²°ê³¼ë¥¼ ë©”ì¸ ë³´ê³ ì„œì— ì¶”ê°€
-            report['operability_summary'] = {
-                'total_forecasts': operability_report['summary']['total_forecasts'],
-                'go_count': operability_report['summary']['go_count'],
-                'conditional_count': operability_report['summary']['conditional_count'],
-                'nogo_count': operability_report['summary']['nogo_count'],
-                'average_confidence': operability_report['summary']['average_confidence']
+            report["operability_summary"] = {
+                "total_forecasts": operability_report["summary"]["total_forecasts"],
+                "go_count": operability_report["summary"]["go_count"],
+                "conditional_count": operability_report["summary"]["conditional_count"],
+                "nogo_count": operability_report["summary"]["nogo_count"],
+                "average_confidence": operability_report["summary"][
+                    "average_confidence"
+                ],
             }
-            
+
             # ìš´í•­ ê°€ëŠ¥ì„± CSV ì €ì¥
             import pandas as pd
-            if operability_report['operability_forecasts']:
+
+            if operability_report["operability_forecasts"]:
                 csv_data = []
-                for forecast in operability_report['operability_forecasts']:
-                    csv_data.append({
-                        'day': forecast.day,
-                        'daypart': forecast.daypart,
-                        'P_go': forecast.probabilities.P_go,
-                        'P_cond': forecast.probabilities.P_cond,
-                        'P_nogo': forecast.probabilities.P_nogo,
-                        'decision': forecast.decision,
-                        'confidence': forecast.confidence
-                    })
-                
+                for forecast in operability_report["operability_forecasts"]:
+                    csv_data.append(
+                        {
+                            "day": forecast.day,
+                            "daypart": forecast.daypart,
+                            "P_go": forecast.probabilities.P_go,
+                            "P_cond": forecast.probabilities.P_cond,
+                            "P_nogo": forecast.probabilities.P_nogo,
+                            "decision": forecast.decision,
+                            "confidence": forecast.confidence,
+                        }
+                    )
+
                 df = pd.DataFrame(csv_data)
                 operability_csv = Path(args.out) / "operability_forecasts.csv"
                 df.to_csv(operability_csv, index=False)
                 print(f"  âœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì €ì¥: {operability_csv}")
-            
-            print(f"  âœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì™„ë£Œ: GO {operability_report['summary']['go_count']}ê°œ, "
-                  f"CONDITIONAL {operability_report['summary']['conditional_count']}ê°œ, "
-                  f"NO-GO {operability_report['summary']['nogo_count']}ê°œ")
-                  
+
+            print(
+                f"  âœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì™„ë£Œ: GO {operability_report['summary']['go_count']}ê°œ, "
+                f"CONDITIONAL {operability_report['summary']['conditional_count']}ê°œ, "
+                f"NO-GO {operability_report['summary']['nogo_count']}ê°œ"
+            )
+
         except Exception as e:
             print(f"  âš ï¸ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
-            report['operability_summary'] = {'error': str(e)}
-        
+            report["operability_summary"] = {"error": str(e)}
+
         # ì„±ê³µ ë©”ì‹œì§€
-        data_rate = report['summary_json']['collection_stats']['data_collection_rate']
+        data_rate = report["summary_json"]["collection_stats"]["data_collection_rate"]
         print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ!")
         print(f"ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ë¥ : {data_rate:.1f}%")
         print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í„°ë¦¬: {args.out}")
-        
+
         return True
-        
+
     except Exception as e:
         print(f"âŒ ì‘ì—… ì‹¤íŒ¨: {e}")
         import traceback
+
         traceback.print_exc()
         return False
 
+
 if __name__ == "__main__":
     success = main()
     sys.exit(0 if success else 1)
diff --git a/src/marine_ops/eri/compute.py b/src/marine_ops/eri/compute.py
index 969961a25b5d2a77af4d665bdcc8691a12b55366..a4418c2948c6a4fae010b2d575b77873f8e292cc 100644
--- a/src/marine_ops/eri/compute.py
+++ b/src/marine_ops/eri/compute.py
@@ -1,258 +1,288 @@
 # KR: ERI (Environmental Risk Index) ê³„ì‚°
 # EN: Environmental Risk Index computation
 
-import yaml
 import json
-from pathlib import Path
-from typing import Dict, List, Any, Tuple
+from copy import deepcopy
 from datetime import datetime
+from pathlib import Path
+from typing import Any, Dict, List, Tuple
+
+import yaml
+
+from src.marine_ops.core.schema import ERIPoint, MarineTimeseries
+
+DEFAULT_ERI_RULES: Dict[str, Any] = {
+    "wind": {
+        "thresholds": [10, 15, 20, 25],
+        "weights": [0.2, 0.4, 0.7, 1.0],
+    },
+    "wave": {
+        "thresholds": [1.0, 1.5, 2.0, 2.5],
+        "weights": [0.2, 0.4, 0.7, 1.0],
+    },
+    "swell": {
+        "thresholds": [0.5, 1.0, 1.5, 2.0],
+        "weights": [0.1, 0.3, 0.6, 1.0],
+    },
+    "wind_wave": {
+        "thresholds": [0.5, 1.0, 1.5, 2.0],
+        "weights": [0.1, 0.3, 0.6, 1.0],
+    },
+    "ocean_current": {
+        "thresholds": [0.5, 1.0, 1.5, 2.0],
+        "weights": [0.1, 0.3, 0.6, 1.0],
+    },
+    "visibility": {
+        "thresholds": [10, 5, 2, 1],
+        "weights": [0.1, 0.3, 0.6, 1.0],
+    },
+    "fog": {
+        "thresholds": [0.1, 0.3, 0.5, 0.7],
+        "weights": [0.2, 0.4, 0.7, 1.0],
+    },
+    "sea_surface_temp": {
+        "thresholds": [20, 25, 30, 35],
+        "weights": [0.1, 0.2, 0.3, 0.5],
+    },
+}
 
-from src.marine_ops.core.schema import MarineTimeseries, ERIPoint
 
 class ERICalculator:
     """ERI ê³„ì‚°ê¸°"""
-    
+
     def __init__(self, rules_file: str = "config/eri_rules.yaml"):
         self.rules_file = Path(rules_file)
         self.rules = self._load_rules()
-    
+
     def _load_rules(self) -> Dict[str, Any]:
-        """ERI ê·œì¹™ ë¡œë“œ"""
+        """ERI ê·œì¹™ ë¡œë“œ / Load ERI rules."""
+        merged_rules = deepcopy(DEFAULT_ERI_RULES)
+
         if self.rules_file.exists():
-            with open(self.rules_file, 'r', encoding='utf-8') as f:
-                return yaml.safe_load(f)
-        else:
-            # ê¸°ë³¸ ê·œì¹™ (í™•ì¥ë¨)
-            return {
-                'wind': {
-                    'thresholds': [10, 15, 20, 25],  # m/s
-                    'weights': [0.2, 0.4, 0.7, 1.0]
-                },
-                'wave': {
-                    'thresholds': [1.0, 1.5, 2.0, 2.5],  # m
-                    'weights': [0.2, 0.4, 0.7, 1.0]
-                },
-                'swell': {
-                    'thresholds': [0.5, 1.0, 1.5, 2.0],  # m
-                    'weights': [0.1, 0.3, 0.6, 1.0]
-                },
-                'wind_wave': {
-                    'thresholds': [0.5, 1.0, 1.5, 2.0],  # m
-                    'weights': [0.1, 0.3, 0.6, 1.0]
-                },
-                'ocean_current': {
-                    'thresholds': [0.5, 1.0, 1.5, 2.0],  # m/s
-                    'weights': [0.1, 0.3, 0.6, 1.0]
-                },
-                'visibility': {
-                    'thresholds': [10, 5, 2, 1],  # km
-                    'weights': [0.1, 0.3, 0.6, 1.0]
-                },
-                'fog': {
-                    'thresholds': [0.1, 0.3, 0.5, 0.7],  # probability
-                    'weights': [0.2, 0.4, 0.7, 1.0]
-                },
-                'sea_surface_temp': {
-                    'thresholds': [20, 25, 30, 35],  # Â°C
-                    'weights': [0.1, 0.2, 0.3, 0.5]  # ì˜¨ë„ëŠ” ë‚®ì€ ìœ„í—˜ë„
-                }
-            }
-    
+            with open(self.rules_file, "r", encoding="utf-8") as f:
+                file_rules = yaml.safe_load(f) or {}
+                merged_rules = self._merge_rules(merged_rules, file_rules)
+
+        return merged_rules
+
+    def _merge_rules(
+        self, base: Dict[str, Any], overrides: Dict[str, Any]
+    ) -> Dict[str, Any]:
+        """ERI ê·œì¹™ ë³‘í•© / Merge ERI rule dictionaries."""
+        for key, value in overrides.items():
+            if isinstance(value, dict) and isinstance(base.get(key), dict):
+                base[key] = self._merge_rules(base[key], value)
+            else:
+                base[key] = value
+        return base
+
     def compute_eri_timeseries(self, timeseries: MarineTimeseries) -> List[ERIPoint]:
         """ì‹œê³„ì—´ ë°ì´í„°ì— ëŒ€í•œ ERI ê³„ì‚°"""
         eri_points = []
-        
+
         for data_point in timeseries.data_points:
             # ê° ìš”ì†Œë³„ ìœ„í—˜ë„ ê³„ì‚°
             wind_risk = self._calculate_wind_risk(data_point.wind_speed)
             wave_risk = self._calculate_wave_risk(data_point.wave_height)
             visibility_risk = self._calculate_visibility_risk(data_point.visibility)
             fog_risk = self._calculate_fog_risk(data_point.fog_probability)
-            
+
             # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì „ì²´ ERI ê³„ì‚° (í™•ì¥ëœ ë³€ìˆ˜ í¬í•¨)
             total_eri = (
-                wind_risk * 0.3 +      # í’ì† 30%
-                wave_risk * 0.25 +     # íŒŒê³  25%
-                self._calculate_swell_risk(data_point.swell_wave_height) * 0.15 +  # ìŠ¤ì›° 15%
-                self._calculate_wind_wave_risk(data_point.wind_wave_height) * 0.1 +  # ë°”ëŒíŒŒ 10%
-                self._calculate_ocean_current_risk(data_point.ocean_current_speed) * 0.05 +  # í•´ë¥˜ 5%
-                visibility_risk * 0.1 + # ì‹œì • 10%
-                fog_risk * 0.05        # ì•ˆê°œ 5%
+                wind_risk * 0.3  # í’ì† 30%
+                + wave_risk * 0.25  # íŒŒê³  25%
+                + self._calculate_swell_risk(data_point.swell_wave_height)
+                * 0.15  # ìŠ¤ì›° 15%
+                + self._calculate_wind_wave_risk(data_point.wind_wave_height)
+                * 0.1  # ë°”ëŒíŒŒ 10%
+                + self._calculate_ocean_current_risk(data_point.ocean_current_speed)
+                * 0.05  # í•´ë¥˜ 5%
+                + visibility_risk * 0.1  # ì‹œì • 10%
+                + fog_risk * 0.05  # ì•ˆê°œ 5%
             )
-            
+
             eri_point = ERIPoint(
                 timestamp=data_point.timestamp,
                 eri_value=total_eri,
                 wind_contribution=wind_risk,
                 wave_contribution=wave_risk,
                 visibility_contribution=visibility_risk,
-                fog_contribution=fog_risk
+                fog_contribution=fog_risk,
             )
             eri_points.append(eri_point)
-        
+
         return eri_points
-    
+
     def _calculate_wind_risk(self, wind_speed: float) -> float:
         """í’ì† ìœ„í—˜ë„ ê³„ì‚°"""
-        thresholds = self.rules['wind']['thresholds']
-        weights = self.rules['wind']['weights']
-        
+        thresholds = self.rules["wind"]["thresholds"]
+        weights = self.rules["wind"]["weights"]
+
         if wind_speed < thresholds[0]:
             return weights[0]
         elif wind_speed < thresholds[1]:
             return weights[1]
         elif wind_speed < thresholds[2]:
             return weights[2]
         elif wind_speed < thresholds[3]:
             return weights[3]
         else:
             return 1.0  # ìµœëŒ€ ìœ„í—˜
-    
+
     def _calculate_wave_risk(self, wave_height: float) -> float:
         """íŒŒê³  ìœ„í—˜ë„ ê³„ì‚°"""
-        thresholds = self.rules['wave']['thresholds']
-        weights = self.rules['wave']['weights']
-        
+        thresholds = self.rules["wave"]["thresholds"]
+        weights = self.rules["wave"]["weights"]
+
         if wave_height < thresholds[0]:
             return weights[0]
         elif wave_height < thresholds[1]:
             return weights[1]
         elif wave_height < thresholds[2]:
             return weights[2]
         elif wave_height < thresholds[3]:
             return weights[3]
         else:
             return 1.0  # ìµœëŒ€ ìœ„í—˜
-    
+
     def _calculate_visibility_risk(self, visibility: float) -> float:
         """ì‹œì • ìœ„í—˜ë„ ê³„ì‚°"""
         if visibility is None:
             return 0.5  # ì¤‘ê°„ ìœ„í—˜ (ë°ì´í„° ì—†ìŒ)
-        
-        thresholds = self.rules['visibility']['thresholds']
-        weights = self.rules['visibility']['weights']
-        
+
+        thresholds = self.rules["visibility"]["thresholds"]
+        weights = self.rules["visibility"]["weights"]
+
         if visibility > thresholds[0]:
             return weights[0]
         elif visibility > thresholds[1]:
             return weights[1]
         elif visibility > thresholds[2]:
             return weights[2]
         elif visibility > thresholds[3]:
             return weights[3]
         else:
             return 1.0  # ìµœëŒ€ ìœ„í—˜
-    
+
     def _calculate_fog_risk(self, fog_probability: float) -> float:
         """ì•ˆê°œ ìœ„í—˜ë„ ê³„ì‚°"""
         if fog_probability is None:
             return 0.1  # ë‚®ì€ ìœ„í—˜ (ë°ì´í„° ì—†ìŒ)
-        
-        thresholds = self.rules['fog']['thresholds']
-        weights = self.rules['fog']['weights']
-        
+
+        thresholds = self.rules["fog"]["thresholds"]
+        weights = self.rules["fog"]["weights"]
+
         if fog_probability < thresholds[0]:
             return weights[0]
         elif fog_probability < thresholds[1]:
             return weights[1]
         elif fog_probability < thresholds[2]:
             return weights[2]
         elif fog_probability < thresholds[3]:
             return weights[3]
         else:
             return 1.0  # ìµœëŒ€ ìœ„í—˜
-    
+
     def _calculate_swell_risk(self, swell_height: float) -> float:
         """ìŠ¤ì›° íŒŒê³  ìœ„í—˜ë„ ê³„ì‚°"""
         if swell_height is None:
             return 0.1  # ë‚®ì€ ìœ„í—˜ (ë°ì´í„° ì—†ìŒ)
-        
-        thresholds = self.rules['swell']['thresholds']
-        weights = self.rules['swell']['weights']
-        
+
+        thresholds = self.rules["swell"]["thresholds"]
+        weights = self.rules["swell"]["weights"]
+
         if swell_height < thresholds[0]:
             return weights[0]
         elif swell_height < thresholds[1]:
             return weights[1]
         elif swell_height < thresholds[2]:
             return weights[2]
         elif swell_height < thresholds[3]:
             return weights[3]
         else:
             return 1.0  # ìµœëŒ€ ìœ„í—˜
-    
+
     def _calculate_wind_wave_risk(self, wind_wave_height: float) -> float:
         """ë°”ëŒíŒŒ ìœ„í—˜ë„ ê³„ì‚°"""
         if wind_wave_height is None:
             return 0.1  # ë‚®ì€ ìœ„í—˜ (ë°ì´í„° ì—†ìŒ)
-        
-        thresholds = self.rules['wind_wave']['thresholds']
-        weights = self.rules['wind_wave']['weights']
-        
+
+        thresholds = self.rules["wind_wave"]["thresholds"]
+        weights = self.rules["wind_wave"]["weights"]
+
         if wind_wave_height < thresholds[0]:
             return weights[0]
         elif wind_wave_height < thresholds[1]:
             return weights[1]
         elif wind_wave_height < thresholds[2]:
             return weights[2]
         elif wind_wave_height < thresholds[3]:
             return weights[3]
         else:
             return 1.0  # ìµœëŒ€ ìœ„í—˜
-    
+
     def _calculate_ocean_current_risk(self, current_speed: float) -> float:
         """í•´ë¥˜ ì†ë„ ìœ„í—˜ë„ ê³„ì‚°"""
         if current_speed is None:
             return 0.1  # ë‚®ì€ ìœ„í—˜ (ë°ì´í„° ì—†ìŒ)
-        
-        thresholds = self.rules['ocean_current']['thresholds']
-        weights = self.rules['ocean_current']['weights']
-        
+
+        thresholds = self.rules["ocean_current"]["thresholds"]
+        weights = self.rules["ocean_current"]["weights"]
+
         if current_speed < thresholds[0]:
             return weights[0]
         elif current_speed < thresholds[1]:
             return weights[1]
         elif current_speed < thresholds[2]:
             return weights[2]
         elif current_speed < thresholds[3]:
             return weights[3]
         else:
             return 1.0  # ìµœëŒ€ ìœ„í—˜
 
-def compute_eri_for_ncm(timeseries: MarineTimeseries, ncm_discount: float = 0.8) -> List[ERIPoint]:
+
+def compute_eri_for_ncm(
+    timeseries: MarineTimeseries, ncm_discount: float = 0.8
+) -> List[ERIPoint]:
     """NCM ë°ì´í„°ì— ëŒ€í•œ íŠ¹ë³„ ERI ê³„ì‚° (í• ì¸ ì ìš©)"""
     calculator = ERICalculator()
     eri_points = calculator.compute_eri_timeseries(timeseries)
-    
+
     # NCM ë°ì´í„°ëŠ” ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë¯€ë¡œ ìœ„í—˜ë„ë¥¼ í• ì¸
     for point in eri_points:
         point.eri_value *= ncm_discount
         point.wind_contribution *= ncm_discount
         point.wave_contribution *= ncm_discount
         point.visibility_contribution *= ncm_discount
         point.fog_contribution *= ncm_discount
-    
+
     return eri_points
 
+
 def save_eri_timeseries(location: str, eri_points: List[ERIPoint]) -> None:
     """ERI ì‹œê³„ì—´ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
     output_dir = Path("out")
     output_dir.mkdir(exist_ok=True)
-    
+
     filename = f"eri_{location}.json"
     output_path = output_dir / filename
-    
-    with open(output_path, 'w', encoding='utf-8') as f:
-        json.dump([
-            {
-                'timestamp': point.timestamp,
-                'eri_value': point.eri_value,
-                'wind_contribution': point.wind_contribution,
-                'wave_contribution': point.wave_contribution,
-                'visibility_contribution': point.visibility_contribution,
-                'fog_contribution': point.fog_contribution
-            }
-            for point in eri_points
-        ], f, ensure_ascii=False, indent=2)
-    
+
+    with open(output_path, "w", encoding="utf-8") as f:
+        json.dump(
+            [
+                {
+                    "timestamp": point.timestamp,
+                    "eri_value": point.eri_value,
+                    "wind_contribution": point.wind_contribution,
+                    "wave_contribution": point.wave_contribution,
+                    "visibility_contribution": point.visibility_contribution,
+                    "fog_contribution": point.fog_contribution,
+                }
+                for point in eri_points
+            ],
+            f,
+            ensure_ascii=False,
+            indent=2,
+        )
+
     print(f"ERI ë°ì´í„° ì €ì¥ë¨: {output_path}")

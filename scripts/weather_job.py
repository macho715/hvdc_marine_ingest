#!/usr/bin/env python3
"""
GitHub Actionsìš© í•´ì–‘ ë‚ ì”¨ ì‘ì—… ìŠ¤í¬ë¦½íŠ¸
ë§¤ì‹œê°„ ì‹¤í–‰ë˜ì–´ í•´ì–‘ ë‚ ì”¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import List

import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.marine_ops.connectors.stormglass import StormglassConnector, LOCATIONS as SG_LOCATIONS
from src.marine_ops.connectors.open_meteo import OpenMeteoConnector
from src.marine_ops.connectors.worldtides import create_marine_timeseries_from_worldtides
from src.marine_ops.eri.compute import ERICalculator
from src.marine_ops.decision.fusion import ForecastFusion, OperationalDecisionMaker
from src.marine_ops.core.schema import MarineTimeseries, ERIPoint
from scripts.offline_support import decide_execution_mode, generate_offline_dataset

try:
    from ncm_web.ncm_selenium_ingestor import NCMSeleniumIngestor

    NCM_IMPORT_ERROR: Exception | None = None
except Exception as import_error:  # pragma: no cover - import guard
    NCMSeleniumIngestor = None  # type: ignore[assignment]
    NCM_IMPORT_ERROR = import_error
def load_config(config_path: str) -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            if config_path.endswith('.yml') or config_path.endswith('.yaml'):
                import yaml
                return yaml.safe_load(f)
            else:
                return json.load(f)
    except FileNotFoundError:
        print(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        return {}

def collect_weather_data(location_name: str = "AGI", forecast_hours: int = 24, mode: str = "auto") -> dict:
    """í•´ì–‘ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘"""
    print(f"ğŸŒŠ {location_name} í•´ì—­ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")

    lat, lon = SG_LOCATIONS[location_name]['lat'], SG_LOCATIONS[location_name]['lon']
    now = datetime.now()
    end_date = now + timedelta(hours=forecast_hours)

    mandatory_secrets = ["STORMGLASS_API_KEY"]
    optional_secrets = ["WORLDTIDES_API_KEY"]

    missing_mandatory = [key for key in mandatory_secrets if not os.getenv(key)]
    missing_optional = [key for key in optional_secrets if not os.getenv(key)]

    resolved_mode, offline_reasons = decide_execution_mode(
        mode,
        missing_mandatory,
        NCMSeleniumIngestor is not None,
    )

    if missing_optional:
        print(
            "â„¹ï¸ ì„ íƒ ì‹œí¬ë¦¿ ëˆ„ë½: "
            + ", ".join(missing_optional)
            + " (ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ì€ ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤)"
        )

    if resolved_mode == "offline":
        synthetic_series, statuses = generate_offline_dataset(location_name, forecast_hours)
        if offline_reasons:
            print(f"âš ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì „í™˜: {', '.join(offline_reasons)}")
        return {
            'timeseries': synthetic_series,
            'api_status': statuses,
            'location': location_name,
            'forecast_hours': forecast_hours,
            'collected_at': now.isoformat(),
            'mode': resolved_mode,
            'offline_reasons': offline_reasons,
        }

    all_timeseries: List[MarineTimeseries] = []
    api_status: dict[str, dict[str, float]] = {}

    # API í‚¤ ë¡œë“œ
    stormglass_key = os.getenv('STORMGLASS_API_KEY', '')
    worldtides_key = os.getenv('WORLDTIDES_API_KEY', '')

    # 1. Stormglass ë°ì´í„° ìˆ˜ì§‘
    try:
        if stormglass_key:
            sg_connector = StormglassConnector(api_key=stormglass_key)
            sg_timeseries = sg_connector.get_marine_weather(lat, lon, now, end_date, location=location_name)
            all_timeseries.append(sg_timeseries)
            api_status['STORMGLASS'] = {
                'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
                'confidence': getattr(sg_timeseries, 'confidence', 0.5)
            }
            print(f"âœ… Stormglass: {len(sg_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        else:
            api_status['STORMGLASS'] = {'status': 'âŒ API í‚¤ ì—†ìŒ', 'confidence': 0.0}
            print("âŒ Stormglass API í‚¤ ì—†ìŒ")
    except Exception as e:
        print(f"âŒ Stormglass ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        api_status['STORMGLASS'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}

    # 2. Open-Meteo ë°ì´í„° ìˆ˜ì§‘
    try:
        om_connector = OpenMeteoConnector()
        om_timeseries = om_connector.get_marine_weather(lat, lon, now, end_date, location=location_name)
        all_timeseries.append(om_timeseries)
        api_status['OPEN_METEO'] = {
            'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
            'confidence': getattr(om_timeseries, 'confidence', 0.5)
        }
        print(f"âœ… Open-Meteo: {len(om_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
    except Exception as e:
        print(f"âŒ Open-Meteo ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        api_status['OPEN_METEO'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}

    # 3. NCM Selenium ë°ì´í„° ìˆ˜ì§‘
    if NCMSeleniumIngestor is None:
        api_status['NCM_SELENIUM'] = {'status': 'âŒ ëª¨ë“ˆ ëˆ„ë½', 'confidence': 0.0}
        if NCM_IMPORT_ERROR is not None:
            print(f"âŒ NCM Selenium ë¡œë“œ ì‹¤íŒ¨: {NCM_IMPORT_ERROR}")
    else:
        try:
            ncm_ingestor = NCMSeleniumIngestor(headless=True)
            ncm_timeseries = ncm_ingestor.create_marine_timeseries(location=location_name, forecast_hours=forecast_hours)
            all_timeseries.append(ncm_timeseries)
            api_status['NCM_SELENIUM'] = {
                'status': 'âœ… ì‹¤ì œ ë°ì´í„°' if "fallback" not in ncm_timeseries.source else 'âš ï¸ í´ë°± ë°ì´í„°',
                'confidence': getattr(ncm_timeseries, 'confidence', 0.5)
            }
            print(f"âœ… NCM Selenium: {len(ncm_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        except Exception as e:
            print(f"âŒ NCM Selenium ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            api_status['NCM_SELENIUM'] = {'status': 'âŒ ì‹¤íŒ¨', 'confidence': 0.0}

    # 4. WorldTides ë°ì´í„° ìˆ˜ì§‘ (ì„ íƒì‚¬í•­)
    if worldtides_key:
        try:
            wt_timeseries = create_marine_timeseries_from_worldtides(lat, lon, worldtides_key, forecast_hours, location_name)
            all_timeseries.append(wt_timeseries)
            api_status['WORLDTIDES'] = {
                'status': 'âœ… ì‹¤ì œ ë°ì´í„°',
                'confidence': getattr(wt_timeseries, 'confidence', 0.5)
            }
            print(f"âœ… WorldTides: {len(wt_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        except Exception as e:
            print(f"âš ï¸ WorldTides ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            api_status['WORLDTIDES'] = {'status': 'âš ï¸ í¬ë ˆë”§ ë¶€ì¡±', 'confidence': 0.3}
    else:
        api_status['WORLDTIDES'] = {'status': 'âŒ API í‚¤ ì—†ìŒ', 'confidence': 0.0}

    if not all_timeseries:
        print("âš ï¸ ì™¸ë¶€ ë°ì´í„°ê°€ ì—†ì–´ í•©ì„± ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        synthetic_series, synthetic_status = generate_offline_dataset(location_name, forecast_hours)
        all_timeseries.extend(synthetic_series)
        api_status.update(synthetic_status)
        offline_reasons.append("ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        resolved_mode = "offline"

    return {
        'timeseries': all_timeseries,
        'api_status': api_status,
        'location': location_name,
        'forecast_hours': forecast_hours,
        'collected_at': now.isoformat(),
        'mode': resolved_mode,
        'offline_reasons': offline_reasons,
    }

def analyze_weather_data(data: dict) -> dict:
    """ìˆ˜ì§‘ëœ ë‚ ì”¨ ë°ì´í„° ë¶„ì„"""
    print("ğŸ“Š ë‚ ì”¨ ë°ì´í„° ë¶„ì„ ì¤‘...")
    
    all_timeseries = data['timeseries']
    if not all_timeseries:
        return {'error': 'ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
    
    # ERI ê³„ì‚°
    eri_calculator = ERICalculator()
    all_eri_points = []
    
    for timeseries in all_timeseries:
        eri_points = eri_calculator.compute_eri_timeseries(timeseries)
        all_eri_points.extend(eri_points)
    
    # ì˜ˆë³´ ìœµí•©
    fusion_settings = {
        'ncm_weight': 0.60,
        'system_weight': 0.40,
        'alpha': 0.7,
        'beta': 0.3
    }
    
    forecast_fusion = ForecastFusion(fusion_settings)
    fused_forecasts = forecast_fusion.fuse_forecast_sources(all_timeseries, data['location'])
    
    # ìš´í•­ íŒì •
    decision_settings = {
        'gate': {
            'go': {'hs_m': 1.0, 'wind_kt': 20.0},
            'conditional': {'hs_m': 1.2, 'wind_kt': 22.0}
        },
        'alert_gamma': {
            'rough_at_times': 0.15,
            'high_seas': 0.30
        }
    }
    
    decision_maker = OperationalDecisionMaker(decision_settings)
    decisions = decision_maker.decide_and_eta(fused_forecasts, all_eri_points)
    
    # í†µê³„ ê³„ì‚°
    go_count = sum(1 for d in decisions if d.decision == 'GO')
    conditional_count = sum(1 for d in decisions if d.decision == 'CONDITIONAL')
    no_go_count = sum(1 for d in decisions if d.decision == 'NO-GO')
    
    avg_eri = sum(p.eri_value for p in all_eri_points) / len(all_eri_points) if all_eri_points else 0
    avg_wind_speed = sum(f.wind_speed_fused for f in fused_forecasts) / len(fused_forecasts) if fused_forecasts else 0
    avg_wave_height = sum(f.wave_height_fused for f in fused_forecasts) / len(fused_forecasts) if fused_forecasts else 0
    
    return {
        'total_data_points': sum(len(ts.data_points) for ts in all_timeseries),
        'fused_forecasts': len(fused_forecasts),
        'decisions': {
            'total': len(decisions),
            'GO': go_count,
            'CONDITIONAL': conditional_count,
            'NO-GO': no_go_count
        },
        'averages': {
            'eri': avg_eri,
            'wind_speed_ms': avg_wind_speed,
            'wave_height_m': avg_wave_height
        },
        'eri_points': len(all_eri_points),
        'confidence_scores': [getattr(ts, 'confidence', 0.5) for ts in all_timeseries]
    }

def generate_summary_report(data: dict, analysis: dict, output_dir: str) -> dict:
    """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
    print("ğŸ“ ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    
    # JSON ìš”ì•½
    execution_mode = data.get('mode', 'online')
    success_sources = sum(1 for status in data['api_status'].values() if 'âœ…' in status['status'])
    total_sources = max(len(data['api_status']), 1)
    collection_rate = success_sources / total_sources * 100
    summary_json = {
        'metadata': {
            'generated_at': datetime.now().isoformat(),
            'location': data['location'],
            'forecast_hours': data['forecast_hours'],
            'system_version': 'v2.1',
            'execution_mode': execution_mode,
        },
        'api_status': data['api_status'],
        'analysis': analysis,
        'collection_stats': {
            'total_timeseries': len(data['timeseries']),
            'total_data_points': analysis.get('total_data_points', 0),
            'data_collection_rate': collection_rate,
        }
    }

    if data.get('offline_reasons'):
        summary_json['metadata']['offline_reasons'] = data['offline_reasons']
    
    json_path = output_path / f"summary_{timestamp}.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(summary_json, f, ensure_ascii=False, indent=2)
    
    # CSV ìš”ì•½
    csv_data = []
    for api_name, status in data['api_status'].items():
        csv_data.append({
            'API': api_name,
            'Status': status['status'],
            'Confidence': status['confidence'],
            'Timestamp': datetime.now().isoformat()
        })
    
    csv_path = output_path / f"api_status_{timestamp}.csv"
    df = pd.DataFrame(csv_data)
    df.to_csv(csv_path, index=False, encoding='utf-8')
    
    # í…ìŠ¤íŠ¸ ìš”ì•½
    txt_content = f"""ğŸŒŠ UAE í•´ì—­ í•´ì–‘ ë‚ ì”¨ ë³´ê³ ì„œ
========================================
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
ìœ„ì¹˜: {data['location']} (Al Ghallan Island)
ì˜ˆë³´ ê¸°ê°„: {data['forecast_hours']}ì‹œê°„
ì‹¤í–‰ ëª¨ë“œ: {execution_mode.upper()}
"""

    if data.get('offline_reasons'):
        txt_content += "ì˜¤í”„ë¼ì¸ ì‚¬ìœ : " + "; ".join(data['offline_reasons']) + "\n"

    txt_content += "\nğŸ“Š ë°ì´í„° ìˆ˜ì§‘ í˜„í™©:\n"

    for api_name, status in data['api_status'].items():
        conf = status.get('confidence', None)
        conf_txt = f"{conf:.2f}" if isinstance(conf, (int, float)) else "N/A"
        txt_content += f"  {api_name}: {status['status']} (ì‹ ë¢°ë„: {conf_txt})\n"
    
    txt_content += f"""
ğŸ“ˆ ë¶„ì„ ê²°ê³¼:
  - ì´ ë°ì´í„° í¬ì¸íŠ¸: {analysis.get('total_data_points', 0):,}ê°œ
  - ìœµí•© ì˜ˆë³´: {analysis.get('fused_forecasts', 0)}ê°œ
  - í‰ê·  ERI: {analysis.get('averages', {}).get('eri', 0):.3f}
  - í‰ê·  í’ì†: {analysis.get('averages', {}).get('wind_speed_ms', 0):.1f} m/s
  - í‰ê·  íŒŒê³ : {analysis.get('averages', {}).get('wave_height_m', 0):.2f} m

ğŸš¢ ìš´í•­ íŒì •:
  - GO: {analysis.get('decisions', {}).get('GO', 0)}íšŒ
  - CONDITIONAL: {analysis.get('decisions', {}).get('CONDITIONAL', 0)}íšŒ
  - NO-GO: {analysis.get('decisions', {}).get('NO-GO', 0)}íšŒ

ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {json_path.name}
"""
    
    txt_path = output_path / "summary.txt"
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(txt_content)
    
    print(f"âœ… ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ:")
    print(f"  - JSON: {json_path}")
    print(f"  - CSV: {csv_path}")
    print(f"  - TXT: {txt_path}")
    
    return {
        'json_path': str(json_path),
        'csv_path': str(csv_path),
        'txt_path': str(txt_path),
        'summary_json': summary_json
    }

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—…')
    parser.add_argument('--config', default='config/locations.yml', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--out', default='out', help='ì¶œë ¥ ë””ë ‰í„°ë¦¬')
    parser.add_argument('--location', default='AGI', help='ìœ„ì¹˜ ì½”ë“œ')
    parser.add_argument('--hours', type=int, default=24, help='ì˜ˆë³´ ì‹œê°„')
    parser.add_argument('--mode', choices=['auto', 'online', 'offline'], default='auto', help='ì‹¤í–‰ ëª¨ë“œ (auto/online/offline)')
    
    args = parser.parse_args()
    
    print("ğŸ¤– GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—… ì‹œì‘")
    print("=" * 50)
    
    try:
        # ì„¤ì • ë¡œë“œ
        config = load_config(args.config)
        print(f"âœ… ì„¤ì • ë¡œë“œ: {args.config}")
        
        # ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘
        data = collect_weather_data(args.location, args.hours, args.mode)
        
        # ë°ì´í„° ë¶„ì„
        analysis = analyze_weather_data(data)
        
        # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        report = generate_summary_report(data, analysis, args.out)
        
        # ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰
        try:
            print("\nğŸš¢ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
            from src.marine_ops.operability.api import create_operability_report
            
            # í•­ë¡œ ì •ë³´ ì •ì˜
            routes = [
                {
                    "name": "Abu Dhabi to AGI or DAS",
                    "distance_nm": 65.0,
                    "planned_speed_kt": 12.0,
                    "hs_forecast": 1.2
                }
            ]
            
            # ìš´í•­ ê°€ëŠ¥ì„± ë³´ê³ ì„œ ìƒì„±
            # dataëŠ” ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ MarineTimeseries ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            weather_timeseries = data.get('timeseries', [])
            operability_report = create_operability_report(weather_timeseries, routes, forecast_days=7)
            
            # ìš´í•­ ê°€ëŠ¥ì„± ê²°ê³¼ë¥¼ ë©”ì¸ ë³´ê³ ì„œì— ì¶”ê°€
            report['operability_summary'] = {
                'total_forecasts': operability_report['summary']['total_forecasts'],
                'go_count': operability_report['summary']['go_count'],
                'conditional_count': operability_report['summary']['conditional_count'],
                'nogo_count': operability_report['summary']['nogo_count'],
                'average_confidence': operability_report['summary']['average_confidence']
            }
            
            # ìš´í•­ ê°€ëŠ¥ì„± CSV ì €ì¥
            import pandas as pd
            if operability_report['operability_forecasts']:
                csv_data = []
                for forecast in operability_report['operability_forecasts']:
                    csv_data.append({
                        'day': forecast.day,
                        'daypart': forecast.daypart,
                        'P_go': forecast.probabilities.P_go,
                        'P_cond': forecast.probabilities.P_cond,
                        'P_nogo': forecast.probabilities.P_nogo,
                        'decision': forecast.decision,
                        'confidence': forecast.confidence
                    })
                
                df = pd.DataFrame(csv_data)
                operability_csv = Path(args.out) / "operability_forecasts.csv"
                df.to_csv(operability_csv, index=False)
                print(f"  âœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì €ì¥: {operability_csv}")
            
            print(f"  âœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì™„ë£Œ: GO {operability_report['summary']['go_count']}ê°œ, "
                  f"CONDITIONAL {operability_report['summary']['conditional_count']}ê°œ, "
                  f"NO-GO {operability_report['summary']['nogo_count']}ê°œ")
                  
        except Exception as e:
            print(f"  âš ï¸ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            report['operability_summary'] = {'error': str(e)}
        
        # ì„±ê³µ ë©”ì‹œì§€
        data_rate = report['summary_json']['collection_stats']['data_collection_rate']
        print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ!")
        print(f"ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ë¥ : {data_rate:.1f}%")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í„°ë¦¬: {args.out}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì‘ì—… ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)

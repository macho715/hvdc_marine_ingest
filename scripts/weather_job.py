#!/usr/bin/env python3
"""
GitHub Actionsìš© í•´ì–‘ ë‚ ì”¨ ì‘ì—… ìŠ¤í¬ë¦½íŠ¸
ë§¤ì‹œê°„ ì‹¤í–‰ë˜ì–´ í•´ì–‘ ë‚ ì”¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import argparse
import json
import math
import os
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import List, Tuple

import pandas as pd

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.marine_ops.connectors.open_meteo import OpenMeteoConnector
from src.marine_ops.connectors.stormglass import LOCATIONS as SG_LOCATIONS
from src.marine_ops.connectors.stormglass import StormglassConnector
from src.marine_ops.connectors.worldtides import (
    create_marine_timeseries_from_worldtides,
)
from src.marine_ops.core.schema import (
    ERIPoint,
    MarineDataPoint,
    MarineTimeseries,
    OperationalDecision,
)
from src.marine_ops.decision.fusion import ForecastFusion, OperationalDecisionMaker
from src.marine_ops.eri.compute import ERICalculator
from scripts.offline_support import decide_execution_mode, generate_offline_dataset
from scripts.three_day_formatter import ThreeDayFormatter

try:
    from ncm_web.ncm_selenium_ingestor import NCMSeleniumIngestor

    NCM_IMPORT_ERROR: Exception | None = None
except Exception as import_error:  # pragma: no cover - import guard
    NCMSeleniumIngestor = None  # type: ignore[assignment]
    NCM_IMPORT_ERROR = import_error


def create_mock_timeseries(
    source_name: str,
    location: str,
    forecast_hours: int,
    base_time: datetime,
    reason: str,
    confidence: float = 0.35,
) -> Tuple[MarineTimeseries, dict]:
    """ëª¨ì˜ í•´ì–‘ ì‹œê³„ì—´ ìƒì„± / Generate mock marine timeseries."""

    data_points: List[MarineDataPoint] = []
    for hour_index in range(max(forecast_hours, 12)):
        timestamp = base_time + timedelta(hours=hour_index)
        phase = (hour_index % 12) / 12
        wind_speed = 6.0 + 1.5 * math.sin(math.tau * phase)
        wave_height = 0.8 + 0.3 * math.cos(math.tau * phase)
        data_points.append(
            MarineDataPoint(
                timestamp=timestamp.isoformat(),
                wind_speed=round(wind_speed, 2),
                wind_direction=(90 + hour_index * 15) % 360,
                wave_height=round(max(wave_height, 0.2), 2),
                wind_gust=round(wind_speed * 1.2, 2),
                wave_period=5.0 + 0.5 * math.sin(math.tau * phase),
                wave_direction=(120 + hour_index * 10) % 360,
                visibility=9.5,
                temperature=28.0,
                humidity=0.68,
                swell_wave_height=round(max(wave_height - 0.1, 0.15), 2),
                swell_wave_period=6.0,
                swell_wave_direction=(150 + hour_index * 12) % 360,
                wind_wave_height=round(max(wave_height - 0.05, 0.10), 2),
                wind_wave_period=4.5,
                wind_wave_direction=(60 + hour_index * 14) % 360,
                ocean_current_speed=0.35,
                ocean_current_direction=45.0,
                sea_surface_temperature=27.5,
                sea_level=0.2 * math.sin(math.tau * phase),
                confidence=confidence,
            )
        )

    mock_timeseries = MarineTimeseries(
        source=f"{source_name}_mock",
        location=location,
        data_points=data_points,
        ingested_at=datetime.now(timezone.utc).isoformat(),
        confidence=confidence,
    )

    status_payload = {
        "status": f"âš ï¸ ëª¨ì˜ ë°ì´í„° ({reason})",
        "confidence": confidence,
    }

    return mock_timeseries, status_payload


def load_config(config_path: str) -> dict:
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            if config_path.endswith(".yml") or config_path.endswith(".yaml"):
                import yaml

                return yaml.safe_load(f)
            else:
                return json.load(f)
    except FileNotFoundError:
        print(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        return {}


def collect_weather_data(location_name: str = "AGI", forecast_hours: int = 24, mode: str = "auto") -> dict:
    """í•´ì–‘ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘ / Collect marine weather data."""
    print(f"ğŸŒŠ {location_name} í•´ì—­ ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")

    lat, lon = SG_LOCATIONS[location_name]["lat"], SG_LOCATIONS[location_name]["lon"]
    now = datetime.now()
    end_date = now + timedelta(hours=forecast_hours)

    required_secrets = ["STORMGLASS_API_KEY", "WORLDTIDES_API_KEY"]
    missing_secrets = [key for key in required_secrets if not os.getenv(key)]
    resolved_mode, offline_reasons = decide_execution_mode(mode, missing_secrets, NCMSeleniumIngestor is not None)

    if resolved_mode == "offline":
        synthetic_series, statuses = generate_offline_dataset(location_name, forecast_hours)
        if offline_reasons:
            print(f"âš ï¸ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì „í™˜: {', '.join(offline_reasons)}")
        return {
            'timeseries': synthetic_series,
            'api_status': statuses,
            'location': location_name,
            'forecast_hours': forecast_hours,
            'collected_at': now.isoformat(),
            'mode': resolved_mode,
            'offline_reasons': offline_reasons,
        }

    all_timeseries: List[MarineTimeseries] = []
    api_status: dict[str, dict[str, float]] = {}
    resilience_notes: List[str] = []

    # API í‚¤ ë¡œë“œ
    stormglass_key = os.getenv("STORMGLASS_API_KEY", "")
    worldtides_key = os.getenv("WORLDTIDES_API_KEY", "")

    # 1. Stormglass ë°ì´í„° ìˆ˜ì§‘
    try:
        if stormglass_key:
            sg_connector = StormglassConnector(api_key=stormglass_key)
            sg_timeseries = sg_connector.get_marine_weather(
                lat, lon, now, end_date, location=location_name
            )
            all_timeseries.append(sg_timeseries)
            api_status["STORMGLASS"] = {
                "status": "âœ… ì‹¤ì œ ë°ì´í„°",
                "confidence": getattr(sg_timeseries, "confidence", 0.5),
            }
            print(f"âœ… Stormglass: {len(sg_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        else:
            api_status["STORMGLASS"] = {"status": "âŒ API í‚¤ ì—†ìŒ", "confidence": 0.0}
            print("âŒ Stormglass API í‚¤ ì—†ìŒ")
            mock_ts, status_payload = create_mock_timeseries(
                "stormglass",
                location_name,
                forecast_hours,
                now,
                "API í‚¤ ì—†ìŒ",
            )
            all_timeseries.append(mock_ts)
            api_status["STORMGLASS_FALLBACK"] = status_payload
            resilience_notes.append(
                "Stormglass ì‹¤ë°ì´í„° ëŒ€ì‹  ëª¨ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
            )
    except Exception as e:
        print(f"âŒ Stormglass ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        api_status["STORMGLASS"] = {"status": "âŒ ì‹¤íŒ¨", "confidence": 0.0}
        mock_ts, status_payload = create_mock_timeseries(
            "stormglass",
            location_name,
            forecast_hours,
            now,
            "ìš”ì²­ ì‹¤íŒ¨",
        )
        all_timeseries.append(mock_ts)
        api_status["STORMGLASS_FALLBACK"] = status_payload
        resilience_notes.append(
            "Stormglass í˜¸ì¶œ ì‹¤íŒ¨ë¡œ ìë™ ìƒì„± ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
        )

    # 2. Open-Meteo ë°ì´í„° ìˆ˜ì§‘
    try:
        om_connector = OpenMeteoConnector()
        om_timeseries = om_connector.get_marine_weather(
            lat, lon, now, end_date, location=location_name
        )
        all_timeseries.append(om_timeseries)
        api_status["OPEN_METEO"] = {
            "status": "âœ… ì‹¤ì œ ë°ì´í„°",
            "confidence": getattr(om_timeseries, "confidence", 0.5),
        }
        print(f"âœ… Open-Meteo: {len(om_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
    except Exception as e:
        print(f"âŒ Open-Meteo ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        api_status["OPEN_METEO"] = {"status": "âŒ ì‹¤íŒ¨", "confidence": 0.0}
        mock_ts, status_payload = create_mock_timeseries(
            "open_meteo",
            location_name,
            forecast_hours,
            now,
            "ìš”ì²­ ì‹¤íŒ¨",
            confidence=0.4,
        )
        all_timeseries.append(mock_ts)
        api_status["OPEN_METEO_FALLBACK"] = status_payload
        resilience_notes.append("Open-Meteo ì‘ë‹µ ì‹¤íŒ¨ë¡œ ëª¨ì˜ ë°ì´í„°ë¥¼ í•©ì„±í–ˆìŠµë‹ˆë‹¤.")

    # 3. NCM Selenium ë°ì´í„° ìˆ˜ì§‘
    if NCMSeleniumIngestor is None:
        api_status['NCM_SELENIUM'] = {'status': 'âŒ ëª¨ë“ˆ ëˆ„ë½', 'confidence': 0.0}
        if NCM_IMPORT_ERROR is not None:
            print(f"âŒ NCM Selenium ë¡œë“œ ì‹¤íŒ¨: {NCM_IMPORT_ERROR}")
    else:
        try:
            ncm_ingestor = NCMSeleniumIngestor(headless=True)
            ncm_timeseries = ncm_ingestor.create_marine_timeseries(
                location=location_name, forecast_hours=forecast_hours
            )
            all_timeseries.append(ncm_timeseries)
            api_status["NCM_SELENIUM"] = {
                "status": (
                    "âœ… ì‹¤ì œ ë°ì´í„°"
                    if "fallback" not in ncm_timeseries.source
                    else "âš ï¸ í´ë°± ë°ì´í„°"
                ),
                "confidence": getattr(ncm_timeseries, "confidence", 0.5),
            }
            print(f"âœ… NCM Selenium: {len(ncm_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        except Exception as e:
            print(f"âŒ NCM Selenium ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            api_status["NCM_SELENIUM"] = {"status": "âŒ ì‹¤íŒ¨", "confidence": 0.0}
            mock_ts, status_payload = create_mock_timeseries(
                "ncm",
                location_name,
                forecast_hours,
                now,
                "ì…€ë ˆëŠ„ ì‹¤íŒ¨",
                confidence=0.3,
            )
            all_timeseries.append(mock_ts)
            api_status["NCM_SELENIUM_FALLBACK"] = status_payload
            resilience_notes.append("NCM Selenium ëŒ€ì‹  ëª¨ì˜ ìš´í•­ ë°ì´í„°ë¥¼ ì£¼ì…í–ˆìŠµë‹ˆë‹¤.")

    # 4. WorldTides ë°ì´í„° ìˆ˜ì§‘ (ì„ íƒì‚¬í•­)
    if worldtides_key:
        try:
            wt_timeseries = create_marine_timeseries_from_worldtides(
                lat, lon, worldtides_key, forecast_hours, location_name
            )
            all_timeseries.append(wt_timeseries)
            api_status["WORLDTIDES"] = {
                "status": "âœ… ì‹¤ì œ ë°ì´í„°",
                "confidence": getattr(wt_timeseries, "confidence", 0.5),
            }
            print(f"âœ… WorldTides: {len(wt_timeseries.data_points)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
        except Exception as e:
            print(f"âš ï¸ WorldTides ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            api_status["WORLDTIDES"] = {"status": "âš ï¸ í¬ë ˆë”§ ë¶€ì¡±", "confidence": 0.3}
            mock_ts, status_payload = create_mock_timeseries(
                "worldtides",
                location_name,
                forecast_hours,
                now,
                "í¬ë ˆë”§ ë¶€ì¡±",
                confidence=0.32,
            )
            all_timeseries.append(mock_ts)
            api_status["WORLDTIDES_FALLBACK"] = status_payload
            resilience_notes.append(
                "WorldTides í¬ë ˆë”§ ë¶€ì¡± ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ê²°í•©í–ˆìŠµë‹ˆë‹¤."
            )
    else:
        api_status["WORLDTIDES"] = {"status": "âŒ API í‚¤ ì—†ìŒ", "confidence": 0.0}
        mock_ts, status_payload = create_mock_timeseries(
            "worldtides",
            location_name,
            forecast_hours,
            now,
            "API í‚¤ ì—†ìŒ",
            confidence=0.3,
        )
        all_timeseries.append(mock_ts)
        api_status["WORLDTIDES_FALLBACK"] = status_payload
        resilience_notes.append(
            "WorldTides API í‚¤ ë¶€ì¬ ì‹œ ëª¨ì˜ ì¡°ì„ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤."
        )

    if not all_timeseries:
        print("âš ï¸ ì™¸ë¶€ ë°ì´í„°ê°€ ì—†ì–´ í•©ì„± ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        synthetic_series, synthetic_status = generate_offline_dataset(location_name, forecast_hours)
        all_timeseries.extend(synthetic_series)
        api_status.update(synthetic_status)
        offline_reasons.append("ì™¸ë¶€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        resolved_mode = "offline"

    return {
        "timeseries": all_timeseries,
        "api_status": api_status,
        "location": location_name,
        "forecast_hours": forecast_hours,
        "collected_at": now.isoformat(),
        "mode": resolved_mode,
        "offline_reasons": offline_reasons,
        "resilience_notes": resilience_notes,
    }


def analyze_weather_data(data: dict) -> dict:
    """ìˆ˜ì§‘ëœ ë‚ ì”¨ ë°ì´í„° ë¶„ì„"""
    print("ğŸ“Š ë‚ ì”¨ ë°ì´í„° ë¶„ì„ ì¤‘...")

    all_timeseries = data["timeseries"]
    if not all_timeseries:
        return {"error": "ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}

    # ERI ê³„ì‚°
    eri_calculator = ERICalculator()
    all_eri_points = []

    for timeseries in all_timeseries:
        eri_points = eri_calculator.compute_eri_timeseries(timeseries)
        all_eri_points.extend(eri_points)

    # ì˜ˆë³´ ìœµí•©
    fusion_settings = {
        "ncm_weight": 0.60,
        "system_weight": 0.40,
        "alpha": 0.7,
        "beta": 0.3,
    }

    forecast_fusion = ForecastFusion(fusion_settings)
    fused_forecasts = forecast_fusion.fuse_forecast_sources(
        all_timeseries, data["location"]
    )

    # ìš´í•­ íŒì •
    decision_settings = {
        "gate": {
            "go": {"hs_m": 1.0, "wind_kt": 20.0},
            "conditional": {"hs_m": 1.2, "wind_kt": 22.0},
        },
        "alert_gamma": {"rough_at_times": 0.15, "high_seas": 0.30},
    }

    decision_maker = OperationalDecisionMaker(decision_settings)
    decisions = decision_maker.decide_and_eta(fused_forecasts, all_eri_points)

    # í†µê³„ ê³„ì‚°
    go_count = sum(1 for d in decisions if d.decision == "GO")
    conditional_count = sum(1 for d in decisions if d.decision == "CONDITIONAL")
    no_go_count = sum(1 for d in decisions if d.decision == "NO-GO")

    avg_eri = (
        sum(p.eri_value for p in all_eri_points) / len(all_eri_points)
        if all_eri_points
        else 0
    )
    avg_wind_speed = (
        sum(f.wind_speed_fused for f in fused_forecasts) / len(fused_forecasts)
        if fused_forecasts
        else 0
    )
    avg_wave_height = (
        sum(f.wave_height_fused for f in fused_forecasts) / len(fused_forecasts)
        if fused_forecasts
        else 0
    )

    return {
        "total_data_points": sum(len(ts.data_points) for ts in all_timeseries),
        "fused_forecasts": len(fused_forecasts),
        "decisions": {
            "total": len(decisions),
            "GO": go_count,
            "CONDITIONAL": conditional_count,
            "NO-GO": no_go_count,
        },
        "averages": {
            "eri": avg_eri,
            "wind_speed_ms": avg_wind_speed,
            "wave_height_m": avg_wave_height,
        },
        "eri_points": len(all_eri_points),
        "confidence_scores": [getattr(ts, "confidence", 0.5) for ts in all_timeseries],
    }


def generate_summary_report(data: dict, analysis: dict, output_dir: str, use_3day_format: bool = True) -> dict:
    """ìš”ì•½ ë³´ê³ ì„œ ìƒì„± / Generate summary report."""
    print("ğŸ“ ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì¤‘...")

    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M")

    # JSON ìš”ì•½
    execution_mode = data.get('mode', 'online')
    success_sources = sum(1 for status in data['api_status'].values() if 'âœ…' in status['status'])
    total_sources = max(len(data['api_status']), 1)
    collection_rate = success_sources / total_sources * 100
    resilience_notes = data.get("resilience_notes", [])

    summary_json = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "location": data["location"],
            "forecast_hours": data["forecast_hours"],
            "system_version": "v2.1",
            "execution_mode": execution_mode,
            "resilience_mode": bool(resilience_notes),
        },
        "api_status": data["api_status"],
        "analysis": analysis,
        "collection_stats": {
            "total_timeseries": len(data["timeseries"]),
            "total_data_points": analysis.get("total_data_points", 0),
            "data_collection_rate": collection_rate,
        },
        "resilience_notes": resilience_notes,
    }

    if data.get('offline_reasons'):
        summary_json['metadata']['offline_reasons'] = data['offline_reasons']

    json_path = output_path / f"summary_{timestamp}.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(summary_json, f, ensure_ascii=False, indent=2)

    # CSV ìš”ì•½
    csv_data = []
    for api_name, status in data["api_status"].items():
        csv_data.append(
            {
                "API": api_name,
                "Status": status["status"],
                "Confidence": status["confidence"],
                "Timestamp": datetime.now().isoformat(),
            }
        )

    csv_path = output_path / f"api_status_{timestamp}.csv"
    df = pd.DataFrame(csv_data)
    df.to_csv(csv_path, index=False, encoding="utf-8")

    # 3-Day GO/NO-GO í¬ë§· ì‚¬ìš©
    if use_3day_format:
        formatter = ThreeDayFormatter(data["location"])
        
        # ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„
        timeseries_for_formatter = []
        for ts in data.get("timeseries", []):
            for dp in ts.data_points:
                ts_str = dp.timestamp if isinstance(dp.timestamp, str) else dp.timestamp.isoformat()
                timeseries_for_formatter.append({
                    'timestamp': ts_str,
                    'wave_height_m': getattr(dp, 'wave_height_m', 0),
                    'wind_speed_ms': getattr(dp, 'wind_speed_ms', 0),
                })
        
        # Telegramìš© ë©”ì‹œì§€
        txt_content = formatter.generate_telegram_message(summary_json, timeseries_for_formatter)
        
        # Emailìš© HTML
        html_content = formatter.generate_email_html(summary_json, timeseries_for_formatter)
    else:
        # ê¸°ì¡´ í¬ë§· (í˜¸í™˜ì„±)
        txt_content = f"""ğŸŒŠ UAE í•´ì—­ í•´ì–‘ ë‚ ì”¨ ë³´ê³ ì„œ
========================================
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
ìœ„ì¹˜: {data['location']} (Al Ghallan Island)
ì˜ˆë³´ ê¸°ê°„: {data['forecast_hours']}ì‹œê°„
ì‹¤í–‰ ëª¨ë“œ: {execution_mode.upper()}
"""

        if data.get('offline_reasons'):
            txt_content += "ì˜¤í”„ë¼ì¸ ì‚¬ìœ : " + "; ".join(data['offline_reasons']) + "\n"

        txt_content += "\nğŸ“Š ë°ì´í„° ìˆ˜ì§‘ í˜„í™©:\n"

        for api_name, status in data["api_status"].items():
            conf = status.get("confidence", None)
            conf_txt = f"{conf:.2f}" if isinstance(conf, (int, float)) else "N/A"
            txt_content += f"  {api_name}: {status['status']} (ì‹ ë¢°ë„: {conf_txt})\n"

        txt_content += f"""
ğŸ“ˆ ë¶„ì„ ê²°ê³¼:
  - ì´ ë°ì´í„° í¬ì¸íŠ¸: {analysis.get('total_data_points', 0):,}ê°œ
  - ìœµí•© ì˜ˆë³´: {analysis.get('fused_forecasts', 0)}ê°œ
  - í‰ê·  ERI: {analysis.get('averages', {}).get('eri', 0):.3f}
  - í‰ê·  í’ì†: {analysis.get('averages', {}).get('wind_speed_ms', 0):.1f} m/s
  - í‰ê·  íŒŒê³ : {analysis.get('averages', {}).get('wave_height_m', 0):.2f} m

ğŸš¢ ìš´í•­ íŒì •:
  - GO: {analysis.get('decisions', {}).get('GO', 0)}íšŒ
  - CONDITIONAL: {analysis.get('decisions', {}).get('CONDITIONAL', 0)}íšŒ
  - NO-GO: {analysis.get('decisions', {}).get('NO-GO', 0)}íšŒ

ğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {json_path.name}
"""

        if resilience_notes:
            txt_content += "\nğŸ›¡ï¸ ì‹œìŠ¤í…œ ì•ˆì •í™” ë©”ëª¨:\n"
            for note in resilience_notes:
                txt_content += f"  - {note}\n"

        # HTML ìš”ì•½ (Emailìš©) - ê¸°ì¡´ í¬ë§·
        html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        h1 {{ color: #0066cc; }}
        .section {{ margin: 20px 0; }}
        .status {{ padding: 5px; margin: 2px 0; }}
        .success {{ color: #00aa00; }}
        .warning {{ color: #ff9900; }}
        .error {{ color: #cc0000; }}
        table {{ border-collapse: collapse; width: 100%; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #0066cc; color: white; }}
    </style>
</head>
<body>
    <h1>ğŸŒŠ UAE í•´ì—­ í•´ì–‘ ë‚ ì”¨ ë³´ê³ ì„œ</h1>
    <div class="section">
        <p><strong>ìƒì„± ì‹œê°„:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}</p>
        <p><strong>ìœ„ì¹˜:</strong> {data['location']} (Al Ghallan Island)</p>
        <p><strong>ì˜ˆë³´ ê¸°ê°„:</strong> {data['forecast_hours']}ì‹œê°„</p>
        <p><strong>ì‹¤í–‰ ëª¨ë“œ:</strong> {execution_mode.upper()}</p>
"""
    
    if data.get('offline_reasons'):
        html_content += f"        <p><strong>ì˜¤í”„ë¼ì¸ ì‚¬ìœ :</strong> {'; '.join(data['offline_reasons'])}</p>\n"
    
    html_content += """    </div>
    
    <div class="section">
        <h2>ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ í˜„í™©</h2>
        <table>
            <tr><th>API</th><th>ìƒíƒœ</th><th>ì‹ ë¢°ë„</th></tr>
"""
    
    for api_name, status in data["api_status"].items():
        conf = status.get("confidence", None)
        conf_txt = f"{conf:.2f}" if isinstance(conf, (int, float)) else "N/A"
        status_class = "success" if "âœ…" in status['status'] else "warning" if "âš ï¸" in status['status'] else "error"
        html_content += f"            <tr class='{status_class}'><td>{api_name}</td><td>{status['status']}</td><td>{conf_txt}</td></tr>\n"
    
    html_content += f"""        </table>
    </div>
    
    <div class="section">
        <h2>ğŸ“ˆ ë¶„ì„ ê²°ê³¼</h2>
        <ul>
            <li>ì´ ë°ì´í„° í¬ì¸íŠ¸: {analysis.get('total_data_points', 0):,}ê°œ</li>
            <li>ìœµí•© ì˜ˆë³´: {analysis.get('fused_forecasts', 0)}ê°œ</li>
            <li>í‰ê·  ERI: {analysis.get('averages', {}).get('eri', 0):.3f}</li>
            <li>í‰ê·  í’ì†: {analysis.get('averages', {}).get('wind_speed_ms', 0):.1f} m/s</li>
            <li>í‰ê·  íŒŒê³ : {analysis.get('averages', {}).get('wave_height_m', 0):.2f} m</li>
        </ul>
    </div>
    
    <div class="section">
        <h2>ğŸš¢ ìš´í•­ íŒì •</h2>
        <ul>
            <li class="success">GO: {analysis.get('decisions', {}).get('GO', 0)}íšŒ</li>
            <li class="warning">CONDITIONAL: {analysis.get('decisions', {}).get('CONDITIONAL', 0)}íšŒ</li>
            <li class="error">NO-GO: {analysis.get('decisions', {}).get('NO-GO', 0)}íšŒ</li>
        </ul>
    </div>
"""
    
    if resilience_notes:
        html_content += """    <div class="section">
        <h2>ğŸ›¡ï¸ ì‹œìŠ¤í…œ ì•ˆì •í™” ë©”ëª¨</h2>
        <ul>
"""
        for note in resilience_notes:
            html_content += f"            <li>{note}</li>\n"
        html_content += """        </ul>
    </div>
"""
    
        html_content += f"""
    <div class="section">
        <p><em>ìƒì„¸ ë³´ê³ ì„œ: {json_path.name}</em></p>
    </div>
</body>
</html>
"""
    
    # íŒŒì¼ ì €ì¥
    txt_path = output_path / "summary.txt"
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(txt_content)
    
    html_path = output_path / "summary.html"
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(html_content)

    print(f"âœ… ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ:")
    print(f"  - JSON: {json_path}")
    print(f"  - CSV: {csv_path}")
    print(f"  - TXT: {txt_path}")
    print(f"  - HTML: {html_path}")

    return {
        "json_path": str(json_path),
        "csv_path": str(csv_path),
        "txt_path": str(txt_path),
        "html_path": str(html_path),
        "summary_json": summary_json,
    }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—…")
    parser.add_argument(
        "--config", default="config/locations.yml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument("--out", default="out", help="ì¶œë ¥ ë””ë ‰í„°ë¦¬")
    parser.add_argument("--location", default="AGI", help="ìœ„ì¹˜ ì½”ë“œ")
    parser.add_argument("--hours", type=int, default=24, help="ì˜ˆë³´ ì‹œê°„")
    parser.add_argument('--mode', choices=['auto', 'online', 'offline'], default='auto', help='ì‹¤í–‰ ëª¨ë“œ (auto/online/offline)')

    args = parser.parse_args()

    print("ğŸ¤– GitHub Actions í•´ì–‘ ë‚ ì”¨ ì‘ì—… ì‹œì‘")
    print("=" * 50)

    try:
        # ì„¤ì • ë¡œë“œ
        config = load_config(args.config)
        print(f"âœ… ì„¤ì • ë¡œë“œ: {args.config}")

        # ë‚ ì”¨ ë°ì´í„° ìˆ˜ì§‘
        data = collect_weather_data(args.location, args.hours, args.mode)

        # ë°ì´í„° ë¶„ì„
        analysis = analyze_weather_data(data)

        # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        report = generate_summary_report(data, analysis, args.out)

        # ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰
        try:
            print("\nğŸš¢ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
            from src.marine_ops.operability.api import create_operability_report

            # í•­ë¡œ ì •ë³´ ì •ì˜
            routes = [
                {
                    "name": "Abu Dhabi to AGI or DAS",
                    "distance_nm": 65.0,
                    "planned_speed_kt": 12.0,
                    "hs_forecast": 1.2,
                }
            ]

            # ìš´í•­ ê°€ëŠ¥ì„± ë³´ê³ ì„œ ìƒì„±
            # dataëŠ” ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ MarineTimeseries ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            weather_timeseries = data.get("timeseries", [])
            operability_report = create_operability_report(
                weather_timeseries, routes, forecast_days=7
            )

            # ìš´í•­ ê°€ëŠ¥ì„± ê²°ê³¼ë¥¼ ë©”ì¸ ë³´ê³ ì„œì— ì¶”ê°€
            report["operability_summary"] = {
                "total_forecasts": operability_report["summary"]["total_forecasts"],
                "go_count": operability_report["summary"]["go_count"],
                "conditional_count": operability_report["summary"]["conditional_count"],
                "nogo_count": operability_report["summary"]["nogo_count"],
                "average_confidence": operability_report["summary"][
                    "average_confidence"
                ],
            }

            # ìš´í•­ ê°€ëŠ¥ì„± CSV ì €ì¥
            import pandas as pd

            if operability_report["operability_forecasts"]:
                csv_data = []
                for forecast in operability_report["operability_forecasts"]:
                    csv_data.append(
                        {
                            "day": forecast.day,
                            "daypart": forecast.daypart,
                            "P_go": forecast.probabilities.P_go,
                            "P_cond": forecast.probabilities.P_cond,
                            "P_nogo": forecast.probabilities.P_nogo,
                            "decision": forecast.decision,
                            "confidence": forecast.confidence,
                        }
                    )

                df = pd.DataFrame(csv_data)
                operability_csv = Path(args.out) / "operability_forecasts.csv"
                df.to_csv(operability_csv, index=False)
                print(f"  âœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì €ì¥: {operability_csv}")

            print(
                f"  âœ… ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì™„ë£Œ: GO {operability_report['summary']['go_count']}ê°œ, "
                f"CONDITIONAL {operability_report['summary']['conditional_count']}ê°œ, "
                f"NO-GO {operability_report['summary']['nogo_count']}ê°œ"
            )

        except Exception as e:
            print(f"  âš ï¸ ìš´í•­ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            report["operability_summary"] = {"error": str(e)}

        # ì„±ê³µ ë©”ì‹œì§€
        data_rate = report["summary_json"]["collection_stats"]["data_collection_rate"]
        print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ!")
        print(f"ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ë¥ : {data_rate:.1f}%")
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í„°ë¦¬: {args.out}")

        return True

    except Exception as e:
        print(f"âŒ ì‘ì—… ì‹¤íŒ¨: {e}")
        import traceback

        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
